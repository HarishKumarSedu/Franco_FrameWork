import json
import logging
import os
import re
import subprocess
import sys
import tarfile
import threading
from importlib import import_module
from time import sleep, time
from typing import Dict, List
from queue import Queue

import embedded_thrift_server
from packaging.version import parse as parse_version
from paramiko import client
from scp import SCPClient, SCPException

class SSH:
    """Wrapper class for Paramiko SSH client class."""

    client = None

    def __init__(self, address: str, username: str, password: str):
        self.address = address
        self.username = username
        self.password = password
        self.client = client.SSHClient()
        self.client.set_missing_host_key_policy(client.AutoAddPolicy())
        logging.getLogger("paramiko").setLevel(logging.WARNING)

    def open(self):
        for i in range(0,3):
            try:
                self.client.connect(self.address, port=22, username=self.username, password=self.password,
                                    look_for_keys=False, allow_agent=False)
                self.scp_client = SCPClient(self.client.get_transport())
                break
            except Exception as err:
                ssh_err = err
        else:
            raise ConnectionError(f"Could not establish SSH connection to {self.address}, "
                                  f"retry limit exceeded. Received {repr(ssh_err)}")

    def sendcommand(self, command):
        if self.client:
            stdin, stdout, stderr = self.client.exec_command(command)
            while not stdout.channel.exit_status_ready():
                # Print data when available
                if stdout.channel.recv_ready():
                    alldata = stdout.channel.recv(1024)
                    prevdata = b"1"
                    while prevdata:
                        prevdata = stdout.channel.recv(1024)
                        alldata += prevdata

                    return str(alldata, "utf8")
        else:
            print("Connection not opened.")

    def communicate(self, command):
        output = None
        retries = 0
        while output == None:
            output = self.sendcommand(command)
            sleep(0.05)
            if retries >= 10:
                raise TimeoutError(f"Retry limit reached. \nCommand: {command}")
            retries += 1
        return output

    def progress(self, filename, size, sent):
        pass

    def scp(self, localpath, remotepath, put=True):
        if put:
            self.scp_client.put(localpath, recursive=True, remote_path=remotepath)
        else:
            self.scp_client.get(remotepath, localpath, recursive=True)

    def scp_relative(self, localpath, remotepath, items):
        """
        SCP's given subdirectories of folder to remote copy
        :param localpath: Path on client to folder
        :param remotepath: Desired destination for partial copy
        :param subdirs: list of strings, names of subdirectories or file
        :return:
        """
        localpath = os.path.expandvars(localpath)
        remotepath = os.path.expandvars(remotepath)
        fw_name = os.path.basename(os.path.realpath(localpath))
        self.sendcommand('cd %s; mkdir -p %s/%s' % (remotepath, remotepath, fw_name))
        remotepath += '/' + fw_name
        for item in os.scandir(localpath):
            if item.name in items:
                self.scp(item.path, remotepath)

    def is_open(self) -> bool:
        """
        Returns connection status of Paramkiko transport. True if connected, False otherwise.

        :return: Connection status
        :rtype: bool
        """
        transport = self.client.get_transport()
        if transport is None:
            return False
        return transport.is_active()

class Progress:

    def __init__(self, num_steps, length, log=None):
        self.num_steps = num_steps
        self.length = length
        self.n = 0
        self.log = log  # TS logging adapter
        self._print = self.log.print if self.log else print
        try:
            dummy_msg = self.log.process('', {})[0]
            dummy_record = self.log.logger.makeRecord(self.log.logger.name, self.log.INFO, 'name',
                                                      None, msg=dummy_msg, args=None, exc_info=None, func='')
            self.indent = ' ' * (len(self.log.handlers[-1].formatter.format(dummy_record)) - 1)
        except:
            self.indent = ''

    def show(self, msg):
        if len(msg) < 60:
            msg += ' ' * (60 - len(msg))
        else:
            msg = msg[0:56] + '...'
        num_filled = int(self.n * self.length / self.num_steps)
        out = self.indent + '[' + '*' * num_filled + ' ' * (self.length - num_filled) + ']\t' + msg
        self._print('\r' + out, end='')

    def step(self, msg):
        if self.n < self.num_steps:
            self.n += 1
        self.show(msg)

    def clear(self):
        self._print('\r' + self.indent + ' ' * (2 + self.num_steps + 50) + '\r', end='')

def reconnect(ssh: SSH) -> SSH:
    """
    Reconstructs broken SSH connection using same arguements.

    :param ssh: Old SSH object
    :type ssh: SSH
    :return: New SSH object in a connected state
    :rtype: SSH
    """
    connected = False
    num_dots = 0
    start = time()
    while not connected and time() - start < 30:
        sys.stdout = sys.__stdout__
        print('\r' + '\033[93m' + 'Reconnecting' + '.'*num_dots + '\033[0m', end="")
        num_dots = (num_dots + 1) % 4
        sys.stdout = None
        try:
            ssh = SSH(*ssh.args)
            ssh.open()
            ssh.communicate("echo test")
            connected = True
        except:
            connected = False
    sys.stdout = sys.__stdout__
    if not connected:
        raise TimeoutError(f"Unable to reconnect ssh({', '.join(ssh.args)})")
    return ssh

def get_ah_python3_version(ssh: SSH):
    """
    Sends a python script down to the controller that looks for the newest python version on the controller, capped to 3.7
    :param ssh: ssh connection to the controller
    :return: string representing python version, ex. '3.5'
    """
    ssh.scp(os.path.dirname(__file__) + "/get_pyversions.py", '/root')
    version = ssh.communicate('python3 /root/get_pyversions.py').strip()
    return version

def update_local_service_files(py_version: str = '3.5'):
    """
    Writes python call to ah_ctrl_server service file using version from py_version.

    :param py_version: version of python that service will use
    :return: None
    """
    with open(os.path.dirname(embedded_thrift_server.__file__) + '/ah_ctrl_server.service', 'r+') as f:
        contents = f.read()
        version = re.search(r'python3\.\d', contents).group(0)
        contents = contents.replace(version, 'python%s' % py_version)
        f.seek(0)
        f.write(contents)
    with open(os.path.dirname(embedded_thrift_server.__file__) + '/start_ah_ctrl_server', 'r+') as f:
        contents = f.read()
        version = re.search(r'python3\.\d', contents).group(0)
        contents = contents.replace(version, 'python%s' % py_version)
        f.seek(0)
        f.write(contents)

def read_version_cache(ssh: SSH, hostname: str):
    """
    Reads from internal cache and returns version data for a specific hostname.

    :param hostname: hostname of host controller
    :return: dictionary
    """
    path ="/home/python_version_cache.json"
    default = {'py_version': '', 'packages': {}, 'netifaces': False}
    try:  # Try to read cache on controller and load json string
        contents = ssh.communicate('cat %s' % path).strip()
        cache_dict = json.loads(contents)
        return cache_dict[hostname] if hostname in cache_dict else default
    except TimeoutError:  # No file exists, make one and return empty dictionary
        ssh.sendcommand('> %s' % path)
        return default

def write_version_cache(ssh: SSH, hostname: str, new_data: dict):
    """
    Saves new_data as entry in cache dictionary, with hostname as the key.

    :param hostname: Hostname of controller e.g. ah3-xxxxxx.local
    :param new_data: Dictionary of version data to store
    :return: None
    """
    path ="/home/python_version_cache.json"
    try:
        contents = ssh.communicate('cat %s' % path)
        cache_dict = json.loads(contents) if contents else {}
    except TimeoutError:
        cache_dict = {hostname: {'packages': {}}}
    if hostname not in cache_dict:
        cache_dict[hostname] = {'packages': {}}
    cache_dict[hostname]['py_version'] = new_data['py_version']
    cache_dict[hostname]['netifaces'] = new_data['netifaces']
    cache_dict[hostname]['packages'].update(new_data['packages'])

    cache_str = json.dumps(cache_dict, indent=4)
    ssh.sendcommand("> %s; echo '%s' > %s" % (path, cache_str, path))


INTERNAL_MODULES = ['cl_test_station', 'embedded_thrift_server', 'yaml', 'thrift2pyi',
                    'pypeg2', 'Pyro5', 'yapf', 'thrift', 'thriftpy2', 'ply', 'bs4',
                    'program_fpga', 'typer', 'click', 'importlib_metadata', 'zipp']


def __tar_filter(tarinfo: tarfile.TarInfo):
    # Filter all FPGA image files
    if tarinfo.name.endswith('.bit') or tarinfo.name.endswith('.bin') or 'ah_ctrl_dotnet' in tarinfo.name:
        return None
    # Filter all component register maps, since those are serialized
    if 'register_maps' in tarinfo.name and os.path.splitext(tarinfo.name)[1] in ['.json', '.csv', '_wisce.xml', '.svd']:
        return None
    # Filter all pycache directories
    if '__pycache__' in tarinfo.name:
        return None
    # Filter windows files
    if tarinfo.name.endswith('.dll') or tarinfo.name.endswith('.exe'):
        return None
    return tarinfo

def __install_tar_package(ssh, bar, log, tar_path, dist_path, version):
    pkg_name = os.path.basename(tar_path)
    raw_pkg_name = os.path.splitext(pkg_name)[0]
    bar.step("Updating " + raw_pkg_name)
    for trial in range(3):  # Attempt to scp tarfile
        try:
            bar.show("Downloading %s %s" % (pkg_name, version))
            ssh.scp(tar_path, dist_path)
            bar.show("Removing old install")
            ssh.sendcommand('rm -rf %s/%s' % (dist_path, raw_pkg_name))
            bar.show("Extracting %s %s" % (pkg_name, version))
            ssh.sendcommand('tar -C %s -zxf %s ' % (dist_path, dist_path + '/%s' % pkg_name))
            ssh.sendcommand('rm %s' % dist_path + '/%s' % pkg_name)
            # Check if file was successfully installed
            try:
                ssh.communicate(f'ls -fd {dist_path}/{raw_pkg_name}').split('\n')
            except TimeoutError:  # Package does not exists
                continue
            break
        except SCPException:
            ssh = SSH(*ssh.args)
            ssh.sendcommand('rm %s' % dist_path + '/%s' % pkg_name)
            sleep(1)
    else:
        log.error(f"Could not install package: {raw_pkg_name}")
    # Wait for file to be freed, then delete it
    while os.path.exists(tar_path):
        try:
            os.rename(tar_path, tar_path)
        except OSError:
            continue
        os.remove(tar_path)

def __compress_packages(pkg_paths:list, pkg_queue: Queue):
    for pkg_path, version in pkg_paths:
        pkg_name = os.path.basename(pkg_path)
        tar_file = os.path.join(os.path.dirname(__file__), pkg_name + '.tar')
        with tarfile.open(tar_file, 'w:gz') as pkg:  # Create gzip stream
            pkg.add(pkg_path, arcname=pkg_name, filter=__tar_filter)  # Compress local package
        pkg_queue.put((tar_file, version))

def __get_dir_size(path):
    if os.path.isfile(path):
        return os.path.getsize(path)
    total_size = 0
    for p, dirs, files in os.walk(path):
        for f in files:
            fp = os.path.join(p, f)
            total_size += os.path.getsize(fp)
    return total_size

def update_remote_packages(ssh, bar, log, hostname, packages=[], remote_versions={}, py_version='3.5'):
    dist_path = '/usr/local/lib/python%s/dist-packages' % (py_version)
    pkg_paths = []
    this_pkg = None
    for pkg_name in packages:
        update = False
        module = import_module(pkg_name)
        if module is None or module.__file__ is None:
            continue
        if '.dll' in module.__file__:  # Dont install dll packages
            continue
        local_version_str = str(module.__version__) if hasattr(module, '__version__') else 'NO-VERSION'
        # Get local version parse object for comparison
        local_version = parse_version(local_version_str)
        if pkg_name in remote_versions:  # Get remote version and compare
            remote_version = parse_version(remote_versions[pkg_name])
            if remote_version != local_version:  # Out of date, update
                update = True
        else:  # No remote version in cache, update
            update = True

        if update:  # Download package to dist-packages on host controller
            # Get local package path
            pkg_path = os.path.dirname(module.__file__) if module.__file__.endswith('__init__.py') else module.__file__
            # Append to list
            if pkg_name == 'embedded_thrift_server':  # Dont include initialy, this one needs to go first
                this_pkg = (pkg_path, local_version_str)
            else:
                pkg_paths.append((pkg_path, local_version_str))

    # Sort packages alphabetically for consistency
    # pkg_paths = sorted(pkg_paths, key=lambda f: os.path.basename(f[0]))
    pkg_paths = sorted(pkg_paths, key=lambda f: __get_dir_size(f[0]))
    if this_pkg:  # Add embedded_thrift_server to the beggining of list
        pkg_paths.insert(0, this_pkg)

    # Update progress steps
    bar.num_steps += len(pkg_paths)

    # Start compression thread
    processed_pkgs = Queue()
    compression_thread = threading.Thread(target=__compress_packages, args=(pkg_paths, processed_pkgs))
    compression_thread.start()
    for i in range(len(pkg_paths)):
        # Grab compressed archive from Queue
        tar_path, version = processed_pkgs.get()
        pkg_name = os.path.splitext(os.path.basename(tar_path))[0]
        # SCP tar and extract files on remote
        __install_tar_package(ssh, bar, log, tar_path, dist_path, version)
        # Check if package is embedded thrift
        if pkg_name == 'embedded_thrift_server':
            # Copy down the rc.local and val setup script, source the latter to run independent
            bar.show("Setting up remote service")
            setup_server(ssh, hostname, py_version=py_version)
        # Update entry in remote versions
        remote_versions[os.path.splitext(pkg_name)[0]] = version


    # Ensure that compression thread has been killed
    compression_thread.join()

    return remote_versions, bool(pkg_paths)

def install_netifaces(ssh, py_version='3.5'):
    """
    Install netifaces if not already installed. Netifaces is checked separately because it has to be built from source
    instead of copied down
    :param ssh: ssh handle
    :param py_version: version of python to install to
    :return: None
    """
    dist_path = f'/usr/local/lib/python{py_version}/dist-packages'
    server_path = f'{dist_path}/embedded_thrift_server'
    test_script_path = f'{server_path}/utilities/netifaces_check.py'
    python_bin = f'/usr/bin/python{py_version}'
    netifaces_sts = int(ssh.communicate(f'{python_bin} {test_script_path}').split('\n')[0])
    if netifaces_sts is not 1:  # Needs to be installed
        ssh.sendcommand('cd %s/utilities; dos2unix install_netifaces.sh; chmod +x install_netifaces.sh;'
                        './install_netifaces.sh %s' % (server_path, py_version))

def setup_server(ssh, hostname:str, py_version:str = '3.5'):
    """
    Copy down the rc.local and val setup script, source the latter to run independent
    
    :param ssh: SSH handle
    :type ssh: SSH
    :param py_version: python version, used to grab service files from dist-packages
    :type py_version: str
    :return: None
    """
    dist_path = f'/usr/local/lib/python{py_version}/dist-packages'
    server_path = dist_path + '/embedded_thrift_server'
    host_model = hostname[:3].lower()
    if 'ah' in host_model:  # AH only config
        ssh.sendcommand(f'cp {server_path}/{host_model}_rc.local /etc/rc.local')
        ssh.sendcommand('dos2unix /etc/rc.local')
        ssh.sendcommand(f'cp {server_path}/val_ah_config.sh /etc/')
        ssh.sendcommand('dos2unix /etc/val_ah_config.sh; chmod +x /etc/val_ah_config.sh; source /etc/val_ah_config.sh')

    # Set up the ah_ctrl_server to launch in background at startup
    ssh.sendcommand('touch /home/ah_ctrl_server_log.log')  # Create error log file
    ssh.sendcommand(f'cp {server_path}/ah_ctrl_server.service /etc/systemd/system')
    ssh.sendcommand(f"cd {server_path}; dos2unix {server_path}/start_ah_ctrl_server; chmod u+x start_ah_ctrl_server;\
                     systemctl daemon-reload; systemctl enable ah_ctrl_server")

def launch_server(ssh: SSH):
    """
    Launches service and waits for process to appear.
    
    :param ssh: SSH handle
    :type ssh: SSH
    :return:
    """
    ssh.sendcommand('systemctl stop ah_ctrl_server; systemctl start ah_ctrl_server')
    while ssh.sendcommand("ps -elf |grep '[a]h_ctrl_server.py' -o") is None:
        sleep(0.2)
    sleep(1)

def find_hostname(hostname: str, found: threading.Event):
    proc = subprocess.Popen('dns-sd -B _cirruslink._tcp', stdout=subprocess.PIPE)
    line = proc.stdout.readline().decode('utf-8')
    while hostname.lower() not in line.lower():
        line = proc.stdout.readline().decode('utf-8')
    found.set()
    proc.kill()

def sync_and_reboot(hostname: str, ssh: SSH, reconnect_ssh: bool = True, timeout: float = 45.0, bar: Progress = None):
    """
    Issues a sync and reboot to the Zynq device. Polls for host name to reappear using the dns-sd command and then
    reopens the SSH connection.

    :param hostname: Controller hostname
    :type hostname: str
    :param ssh: SSH handle
    :type ssh: SSH
    :param reconnect_ssh:
    :type reconnect_ssh:
    :param bar: Progress bar
    :type bar: Progress
    :param timeout: Time in seconds dns-sd should poll for hostname. If timeout is exceeded, a ConnectionError will be raised
    :type timeout: float
    :return: None
    :rtype: None
    """
    if not bar:
        clear = True
        bar = Progress(num_steps=3, length=10)
    else:
        clear = False
        bar.num_steps += 3
    bar.step("Rebooting...")
    ssh.sendcommand('sync; reboot')
    ssh.client.close()
    if reconnect_ssh:
        # Use dns-sd to poll for hostname
        sleep(10)
        found = threading.Event()
        raw_hostname = hostname.replace('.local', '')  # dns-sd does not include .local
        bar.step(f"Searching for {raw_hostname}...")
        thr = threading.Thread(target=find_hostname, args=(raw_hostname, found), daemon=True)
        thr.start()
        thr.join(timeout - 10)
        if not found.is_set():
            raise ConnectionError(f"Cannot find hostname {hostname}, dns-sd timed out after 45 seconds.")
        bar.step('Reconnecting...')
        for i in range(3):
            try:
                ssh.open()
                break
            except:
                continue
        else:
            raise ConnectionError("Could not reestablish SSH connection")
    if clear:
        bar.clear()

def update_ah(controller, hostname, log, modules=None, force=False):
    """
    Makes sure all modules given are up to date, downloads rc.local and configures service
    Args:
        ssh: SSH object thats already connected to AH
        py_version: String version of python, where the packages will be copied. ex '3.5'
        modules: list of python modules to check for updates
    Returns: clean reference to ssh connection
    """
    if modules is None:
        modules = []
    log.info_line()
    log.info("Updating %s..." % hostname)
    #modules.extend(INTERNAL_MODULES)

    bar = Progress(8, 25, log)
    bar.show("Updating")

    # Grab ssh handle from controller
    ssh = controller.ssh

    # Get AH image version
    image_version = controller.get_image_version()
    try:
        image_version = parse_version(image_version)
    except:
        image_version = parse_version('0.0.0')
        
    if hostname.lower().startswith('ah') and image_version < parse_version('2.4.1'):
        raise Exception(f"AudioHub image ({image_version}) is out of date, requires version >= 2.4.1")

    # Set data to default values
    controller_data = {'py_version': '', 'packages': {}, 'netifaces': False}

    # Load cache if force update is off
    if not force:
        bar.step("Reading cache")
        controller_data = read_version_cache(ssh, hostname)

    # Get python version if force or not saved
    bar.step('Getting python version')
    if not controller_data['py_version']:
        controller_data['py_version'] = get_ah_python3_version(ssh)
    controller.py_version = controller_data['py_version']

    # Update service files with correct python call
    bar.show("Updating local service files")
    update_local_service_files(py_version=controller_data['py_version'])

    # Check SD card partitions
    check_partition_size(ssh, bar)

    # Create list of required packages
    preinstalled = set(ssh.communicate('ls /usr/lib/python3/dist-packages').split())  # Finds all packages shipped with ah image
    py37_incomp = set()  # These preinstalled packages only work with Python3.6
    if image_version < parse_version('2.0.0'):  # Bionic images have more imcompatibilities than focal
        py37_incomp.update({'Pyro4', 'yaml'})
    preinstalled = preinstalled.difference(py37_incomp)  # Remove incompatible packages

    # TODO: Remove this for 2.0.0 - Building list of packages for embedded execution support
    # excluded = {'unified_modules', 'um_framework', 'numpy', 'pandas', 'enum', 'enum.py'}  # Large packages that aren't needed
    # site_pkgs = []

    # Get venv directory
    # venv_dir = None
    # if 'VIRTUAL_ENV' in os.environ:  # Using virtualenv
    #     venv_dir = os.environ['VIRTUAL_ENV']
    # elif 'CONDA_PREFIX' in os.environ:  # Using Anaconda environment
    #     prefix = os.path.normpath(os.environ['CONDA_PREFIX'])  # Path to the conda environment
    #     venv_name = os.environ.get('CONDA_DEFAULT_ENV', os.path.basename(prefix))  # Name of the virtual environment
    #     venv_dir = os.path.join(prefix.partition(os.sep + venv_name)[0], venv_name)  # Get /venv_name/ dir

    # if venv_dir:  # User is in a virtual environment, find all installed and imported packages to install
    #     for sub_dir in ['src', 'Lib/site-packages']:  # Add all files/directories in the venv
    #         site_pkgs.extend(list(os.listdir(os.path.join(venv_dir, sub_dir))))
    #     site_pkgs = [pkg.replace('-', '_').replace('.py', '') for pkg in site_pkgs if 'win32' not in pkg]
    #     site_pkgs = set(site_pkgs)  # Remove any duplicates
    #     req_pkgs = site_pkgs.intersection(set(modules))  # Any packages that are installed AND imported at runtime
    # else:  # Only require necessary packages to run server

    # Remove preinstalled and excluded modules
    modules = list(set(INTERNAL_MODULES).difference(preinstalled))
    # Update packages
    bar.step("Updating packages")
    controller_data['packages'], needs_reboot = update_remote_packages(ssh, bar, log, hostname, packages=modules,
                                                                       remote_versions=controller_data['packages'],
                                                                       py_version=controller_data['py_version'])

    # install netifaces if needed
    bar.step('Checking netifaces')
    if not controller_data['netifaces']:
        install_netifaces(ssh, py_version=controller_data['py_version'])
        controller_data['netifaces'] = True

    # If any pacakges were downloaded, sync/reboot. Fixes issue found on AH rev 3.1, 3.2
    if needs_reboot and 'ah' in hostname.lower():
        sync_and_reboot(hostname, ssh, reconnect_ssh=True, bar=bar)

    # Launch server
    bar.step('Launching server')
    launch_server(ssh)
    bar.step('Saving version data')
    write_version_cache(ssh, hostname, controller_data)
    bar.step("Done!")
    bar.clear()
    log.info(hostname + ' successfully updated.')
    log.info_line()

def validate_version_cache(ssh, hostname):
    missing_modules = []
    cache_dict = read_version_cache(ssh, hostname)  # Get cache dictionary
    py_version = cache_dict['py_version']
    cache_packages = cache_dict['packages']
    dist_path = '/usr/local/lib/python%s/dist-packages' % (py_version)
    # Get real versions for every package in the cache
    get_versions_local = os.path.join(os.path.dirname(embedded_thrift_server.__file__), 'utilities/get_versions.py')
    get_versions_remote = "/root/get_versions.py"
    ssh.scp(get_versions_local, get_versions_remote)
    versions = ssh.communicate(f'python{py_version} {get_versions_remote} {" ".join(cache_packages.keys())}').split('\n')
    # Loop through and compare actual vs cache version
    for pkg_name, cache_version, actual_version in zip(cache_packages.keys(), cache_packages.values(), versions):
        missing = True
        if actual_version == 'none':  # Either the package couldn't be imported or no version available
            # actual_version = 'NO-VERSION'  # Conform to cache format
            for suffix in ['', '.*']:  # Package could be a file or a driectory
                # This command will complete if the file/dir exists. If not, it will raise a TimeOutError
                try:
                    ssh.communicate(f'ls {dist_path}/{pkg_name}{suffix}')
                    missing = False
                    break
                except TimeoutError:
                    continue
        else:  # Package was imported and the version was grabbed successfully
            missing = False
        # This package is either missing or in a broken state
        if missing: # or parse_version(actual_version) != parse_version(cache_version):  # Cache out of sync
            missing_modules.append(pkg_name)
    return missing_modules


def check_partition_size(ssh: SSH, bar: Progress):
    """
    Checks SD card partitions and resizes if mmcblk0p2 failed to expand. Fixes issues seen in AH 2.8.0, 2.9.0

    :param ssh: SSH session
    :type ssh: SSH
    :param bar: Progress Bar
    :type bar: Progress
    :return: None
    :rtype: None
    """
    bar.step('Checking partitions')
    dfh_out = ssh.communicate('df -h')
    # Split output into rows
    dfh_out = dfh_out.split('\n')
    # Create dictionary where key is file system and value is usage summary
    dfh_out: Dict[str, list[str]] = {row.split()[0]: row.split()[1:] for row in dfh_out if row}
    # Get index of Size and Use%
    dev_root = '/dev/root'
    size_index = dfh_out['Filesystem'].index('Size')
    use_pct_index = dfh_out['Filesystem'].index('Use%')
    # Get values from output
    df_size = float(re.match(r'(\d+\.*\d*)[G|M]', dfh_out[dev_root][size_index]).group(1))   # 20%, use 80%
    if 'M' in dfh_out[dev_root][size_index]:  # Convert to gigabytes
        df_size /= 1000
    df_use_pct = int(re.match(r'(\d+)%', dfh_out[dev_root][use_pct_index]).group(1))
    # Call lsblk to get actual partition size
    lsblk_out = ssh.communicate('lsblk')
    lsblk_out = lsblk_out.split('\n')
    lsblk_out: Dict[str, List[str]] = {re.sub(r'└|─|├', '', row.split()[0]): row.split()[1:] for row in lsblk_out if row}
    # Get mmcblk0p2 size
    size_index = lsblk_out['NAME'].index('SIZE')
    mmcblk0p2_size = float(re.match(r'(\d+\.*\d*)[G|M]', lsblk_out['mmcblk0p2'][size_index]).group(1))
    # If the df -h reported size is less than 20% of actual, and use% > 80%, then partition 2 needs resizing
    if df_size/mmcblk0p2_size <= 0.2 and df_use_pct >= 80:
        bar.show('Resizing mmcblk0p2')
        ssh.sendcommand('resize2fs /dev/mmcblk0p2')
        sleep(1)
