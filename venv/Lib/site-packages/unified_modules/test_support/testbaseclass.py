import os
import sys
import re
from time import strftime

from unified_modules.test_support.testframework import TestFrameworkError
from unified_modules.test_support.testheadclient import TestHeadClientError
import unified_modules.test_support.testlogger as logging
import unified_modules.test_support.testoptions as testoptions
from unified_modules.test_support.testresults import TestResults
from unified_modules.test_support.testutils import timeout, get_stack_trace


def set_options(options_class):
    """
    Stores the test options class name to be use by a test class (class
    decorator).

    Example:
        This decorator is to be used with :obj:`BaseTest` or any derivated
        class. Below is an example of how to use it::

            @set_options(TestOptions)
            class SampleTest(BaseTest):

                [...]

    Args:
        options_class (:obj:`type`): the class of option for the test.
    """

    def register_options(cls):
        """Register options class decorator function"""
        setattr(cls, 'options_dec', options_class)
        return cls

    return register_options


def campaigns(campaign_tags):
    """
    Tags a test with campaign it pertains to (class decorator).

    Example:
        This decorator is to be used with :obj:`BaseTest` or any derivated
        class. Below is an example of how to use it::

            @campaigns(['sanity', 'gui']])
            class SampleTest(BaseTest):

                [...]

    Args:
        campaign_tags (:obj:`list` of :obj:`str`): a list of campaign names to
            tag the test with.
    """
    def register_campaigns(cls):
        """Register campaigns decorator function"""
        setattr(cls, 'campaigns', campaign_tags)
        return cls

    return register_campaigns


def dut_types(applicability_tags):
    """
    Tags a test with supported target devices (class decorator).

    Example:
        This decorator is to be used with :obj:`BaseTest` or any derivated
        class. Below is an example of how to use it::

            @dut_types(['fpga', 'silicon']])
            class SampleTest(BaseTest):

                [...]

    Args:
        applicability_tags (:obj:`list` of :obj:`str`): a list of targeted
            device names to tag the test with.
    """
    def register_duts(cls):
        """Register applicable dut/firmware types decorator function"""
        setattr(cls, 'applicability_tags', applicability_tags)
        return cls

    return register_duts


class SharedTestData(object):
    """
    Single class to share data among tests. It is only for data that needs
    to be available to all tests. Reference:Borg-pattern.
    Useful for nested tests.
    """
    __shared_state = {}

    def __init__(self):
        """Initialise shared data"""
        self.__dict__ = self.__shared_state
        self.initiates_done = False


class BaseTest(object):
    """
    Base class for all system tests.

    The test execution process defined by :obj:`BaseTest` relies on:

        - A :func:`setup` method that will be executed by the run method along
          with the setup method of all nested tests. It can be extended to
          organise test options or add parameter sets.

        - An :func:`initiate` method that will be executed by the run method
          followed by the initiate method of all nested tests. It can be
          extended to write the test steps as per a test specification.

        - A :func:`complete` method that will be executed by the run method
          after the complete method of all nested tests. It can be extended to
          perform test result assertions as per a test specification.

        - A :func:`teardown` method that will will be executed by the run method
          along with the teardown method of all nested tests. It can be extended
          to release any resources.

    The execution process supports two extract features:

        - Parameter sets: list of custom arguments to be supply to the
          `initiate()` and `complete()` pair of calls, parameter set per
          parameter set, defining test iterations. See :func:`add_inner_test`.

        - Nested tests: inner tests, also defined as :obj:`BaseTest` tests, that
          will be executed in the context of its parent test. See 
          :func:`add_iteration_lists`.
        """
    options_dec = None

    def __init__(self, result, test_system=None, resources=None, log_prefix="", full_stack_trace=False,
                 target_device=None, uses_local_resources=True):
        """
        Construct a new :obj:`BaseTest` test instance.

        Args:
            result (:obj:`TestResults`): a test result object for assertions.
            test_system (:obj:`TestFramework`, optional): a test framework.
            resources (:obj:`dict`, optional): a dictionary of loaded resources.
            log_prefix (:obj:`str`, optional): the prefix to use for logging.
                Defaults to and empty string, which means the prefix will be
                internally determined (based on the test class name).
            target_device (:obj:`str`, optional): the test execution targeted
                device name. Defaults to `None`.
            uses_local_resources: Runner connected to local resources. Default it to True
        """
        try:
            self.test_name = ""
            self.test_system = test_system
            self.resources = resources
            self.local_resources = {}
            self.full_stack_trace = full_stack_trace
            if not self.resources:
                self.resources = {}
            if result:
                self.result = result
            else:
                self.result = TestResults()
            # Use default options if none provided
            if self.options_dec is None:
                self.options_dec = testoptions.TestOptions

            self.options = self.options_dec()
            self.options.set_test_options()

            if self.test_system:
                self.log_prefix = self.__class__.__name__ + log_prefix
                self.log_folder = self.test_system.get_log_folder()
                self.log = logging.getLogger(self.log_prefix, log_folder=self.log_folder)
            else:
                self.log_prefix = self.__class__.__name__ + log_prefix
                self.log = logging.getLogger(self.log_prefix)

            # TODO: get supported target devices for each test
            if self.options.dry_run_help:
                try:
                    print("Supported variants : ", ','.join(self.applicability_tags))
                except AttributeError:
                    print("No supported variants recorded in test")
                sys.exit(1)

            self.nested_tests = []
            self.parameter_list_list = [[]]
            # TODO: iterations generated from all param combinations: self.parameter_combo_list = []
            self.iteration_count = 1
            # Test name and id not recorded yet. Wait for setup()
            self.test_name_recorded = False
            self.test_id_recorded = False

            # Nested test logic: Test A, TestB. TestC(TestA)- add inner test TestB
            # TestC : run all iterations in B during each iteration of A
            # Iterations of A need to be long enough to run every iteration of B
            # variables for logging purposes
            self.nest_depth = 0
            self.nest_width = 0
            # nested level number
            self.nested_number = 0

            # initialise shared data, all tests will see the same data in this object
            self.shared_data = SharedTestData()

            # TODO: can Jenkins take care of recording versions of source files
            self.record_versions = []

            if self.test_system:
                if not self.test_system.get_target_device():
                    self.test_system.set_target_device(target_device)
                self.test_system.set_results_prefix(self.log_prefix)
                self.test_system.set_uses_local_resources(uses_local_resources)
        except (Exception, KeyboardInterrupt, SystemError):
            self.log.warning("Test terminated before setup, no results to record.")
            raise

        # If inner test fails, safely exit base test
        self.allow_base_to_exit = False

    def setup(self):
        """
        Setup method for test. Base implementation is a no-op.

        Note:
            Sub-classes should override that method in order to perform any pre
            execution operations like resource setup.

        Note:
            Sub-classes **must** register their test name using the
            :func:`record_test_name()` method during the setup phase.
        """
        self.log.debug("SETUP not implemented.")

    def initiate(self, *dummy_args, **dummy_kwargs):
        """
        Initiate method for the test. Base implementation is a no-op.

        The initiate method of all nested will be executed after this method
        This method may be executed more than once if a parameter list has
        been provided in the add_parameter_list method
        Expected to be implemented

        Note:
            Sub-classes are expected to override that method.

        Note:
            This method may be called more than once during test execution: once
            per parameter sets defined at initialisation time.
        """
        self.log.debug("INITIATE method not implemented.")

    def complete(self, *dummy_args, **dummy_kwargs):
        """
        Complete method for test. Base implementation is a no-op.

        Note:
            Sub-classes are expected to override that method.

        Note:
            This method may be called more than once during test execution: once
            per parameter sets defined at initialisation time.
        """
        self.log.debug("COMPLETE not implemented.")

    def teardown(self):
        """
        Teardown method for the test. Base implementation is a no-op.

        Note:
            Sub-classes should override that method in order to perform any post
            execution operations like clean-up or resource disabling.
        """
        self.log.debug("TEARDOWN method not implemented.")

    # XXX: Should we really keep that method?
    def record_result_title(self, result_title):
        """
        Set results title and default logging behaviour.
        """
        self.record_test_name(result_title)

    def record_test_name(self, name=None):
        """
        Sets the test's name. Also sets or modifies the test's log filename to
        contain that name.

        Note:
            This method should only be called once (later calls are ignored).

        Example:
            Every test should call that method as their very first operation
            at ``setup()`` time::

                class SampleTest(BaseTest):

                    [...]

                def setup(self):
                    '''SampleTest setup implementation.'''
                    self.record_test_name(self.__class__.__name__)

                    [...]

        Args:
            name (:obj:`str`): a name for the test (and prefix for log file).
        """
        if self.test_name:
            return

        if not name:
            name = self.__class__.__name__
        self.test_name = name
        self.test_timestamp = strftime('%Y%m%d%H%M%S')
        # Create the logger
        self._create_logger(self.test_name, timestamp=self.test_timestamp)

        # Same results logger for all tests(nested case)
        self.result.set_test_title(self.test_name)
        if self.test_system is not None:
            # Test framework test label is the name supplied.
            self.test_system.label(name)
            self.test_system.set_results_prefix(name)
        else:
            self.log.info("TEST NAME: %s", name)

    def get_target_device(self):
        """
        Gets the test's targeted device name.

        Returns:
            str: the test's targeted device name.
        """
        return self.test_system.get_target_device()

    def get_results_label(self):
        """
        Gets the test's result label.

        Returns:
            str: the test's result label.
        """
        return self.test_system.get_results_label()

    def _create_logger(self, name=None, stdout_formatter=None, timestamp=None):
        """
        Sets up a logger with file handler for the test.

        args:
            name (:obj:`str`, optional): the logger's name. Defaults to `None`,
                which means the test's log prefix will be used as a name.
            stdout_formatter (:obj:`str`, optional): a logger compatible format
                string for the log output. Defaults to `None`.
            timestamp (:obj:`str`, optional): a timestamp to use as a suffix in
                the log filename. Default to `None`, which mean current time
                will be use.
        """
        if name is None:
            name = self.log_prefix
        else:
            self.log_prefix = name
        if self.test_system is None:
            logging.set_filename(name, timestamp=timestamp)
        else:
            logging.set_filename(name, timestamp=timestamp, log_folder=self.get_results_label())
        self.log = logging.getLogger(name, stdout_formatter=stdout_formatter)

    @staticmethod
    def set_log_level(level=logging.DEBUG):
        """
        Adjusts the minimum level of log that should reach output.

        Args:
            level (:obj:`int`, optional): the minimum level required for
                messages to be logged. Default to `DEBUG`.
        """
        logging.disable(level - 1)

    def request_resources(self, resource_reqs):
        """
        Claims a given list of required resources.

        Args:
            resource_reqs (:obj:`list` of :obj:`ResourceRequirement`): a list of
                resources to claim as requirements.
        """
        if self.test_system is not None:
            self.resources.update(self.test_system.startup(resource_reqs))

    # XXX: Should we really keep that method?
    def all_initiates_complete(self):
        """
        Record that all initiate methods in the test are complete.
        """
        return self.shared_data.initiates_done

    def set_parameter_lists(self, parameters_to_add):
        """
        Sets the list of parameter sets, defining test iterations. A parameter
        set is a list of arguments to be pass to the `initiate()` and 
        `complete()` test's methods.

        Example:
            Parameter sets should be declared at initialisation time. Below is
            an example of how to do it::

                class SampleTest(BaseTest):
                    '''Sample test class.'''

                    def __init__(self, result):
                        '''Constructs a new SampleTest instance.'''

                        [...]

                    self.set_parameter_lists([
                        [0x00c212, 0x00],
                        [0x00c214, 0x42],
                    ])

        Note:
            This overwrites any previously defines parameter sets list.

        Args:
            parameters_to_add (list of list): the new list of parameter sets.

        Raises:
            TestFrameworkError: if `parameters_to_add` is not a list.
        """
        self.parameter_list_list = []
        self.add_parameter_lists(parameters_to_add)

    def add_parameter_lists(self, parameters_to_add):
        """
        Appends parameter sets, defining new test iterations. A parameter
        set is a list of arguments to be pass to the `initiate()` and 
        `complete()` test's methods.

        Example:
            Parameter sets should be declared at initialisation time. Below is
            an example of how to do it::

                class SampleTest(BaseTest):
                    '''Sample test class.'''

                    def __init__(self, result):
                        '''Constructs a new SampleTest instance.'''

                        [...]

                    self.add_parameter_lists([
                        [0x00c216, 0x51],
                    ])

        Args:
            parameters_to_add (list of list): the list of parameter sets to add.

        Raises:
            TestFrameworkError: if `parameters_to_add` is not a list.
        """
        if not isinstance(parameters_to_add, list):
            raise TestFrameworkError("testbaseclass-add_parameter_lists - lists takes list of lists.")

        # If we do not have a list of lists, for example a single list of params, convert this to a list of list
        if len(parameters_to_add) != 0:
            if not (isinstance(parameters_to_add[0], list) or isinstance(parameters_to_add[0], tuple)):
                parameters_to_add = [parameters_to_add]

        # Remove default if we have a list with one empty list in it.
        if self.parameter_list_list == [[]]:
            # Remove default entry, reinitialise to empty list.
            self.parameter_list_list = []

        # Concatenate the list of parameters
        self.parameter_list_list = self.parameter_list_list + parameters_to_add

    def add_inner_test(self, test_to_add):
        """
        Appends a nested test to be executed as par of the current test.

        Example:
            Nested tests should be declared at initialisation time. Below is an
            example of how to do it::

                class SampleNestedTest(BaseTest):
                    '''Sample nested test class.'''

                        [...]

                class SampleTest(BaseTest):
                    '''Sample test class.'''

                    def __init__(self, result):
                        '''Constructs a new SampleTest instance.'''

                        [...]

                    self.add_inner_test(
                        SampleNestedTest(result=result)
                    )

        Args:
            test_to_add (:obj:`BaseTest`): the test instance to nest.
        """
        test_to_add.nest_depth = self.nest_depth + 1

        self.nested_number += 1
        test_to_add.nest_width = self.nested_number

        self.nested_tests.append(test_to_add)

    def run_setup(self):
        """
        Executes `setup()` for the test and any of its nested tests.

        Note:
            Setup order always is:
                - Current test setup first.
                - Nested tests setup at last.

        Warning:
            If a sub-class is to override that method, it **must** chain-up to
            that base implementation.
        """
        # MUST run setup first to give setup a chance to:
        # name the test, create the log and add any nested tests.
        self.setup()
        # Run any nested test setups
        for nested_test in self.nested_tests:
            # Pass on a copy of all additional options, if the prefix indicates that it should be
            copy_options = {}
            for option_name, option_value in self.options.new_options.items():
                new_name = re.sub(nested_test.log_prefix + '-', r'', option_name)
                # If the option name was modified then it should be passed on
                if new_name != option_name or new_name == 'help':
                    nested_test.options.opt_prefix = nested_test.log_prefix+'-'
                    copy_options[new_name] = option_value

            nested_test.options.add_new_options(copy_options)
            # nested prefix
            nested_test.log_prefix = self.log_prefix + "-" + nested_test.log_prefix
            nested_test.log = logging.getLogger(nested_test.log_prefix)
            nested_test.run_setup()

    def run_teardown(self):
        """
        Executes `teardown()` for the test and any of its nested tests.

        Note:
            Shut-down order always is:
                - Nested tests teardown first.
                - Current test teardown at last.

        Warning:
            If a sub-class is to override that method, it **must** chain-up to
            that base implementation.
        """
        # Run any nested test teardowns
        for nested_test in reversed(self.nested_tests):
            try:
                nested_test.run_teardown()

            # pylint: disable=broad-except
            # catch any exception and continue with cleanup anyway
            except Exception:
                self.log.warning("WARNING: teardown failed - %s", get_stack_trace(self.full_stack_trace))
        self.teardown()

    def run_test(self):
        """
        Executes 'initiate()' and 'complete()' for the test and any of its
        nested tests.

        Note:
            Execution order always is:
                - Current test initialisation first.
                - Nested tests initialisation then.
                - Nested tests completion after.
                - Current test completion at last.

        Warning:
            If a sub-class is to override that method, it **must** chain-up to
            that base implementation.
        """
        # TODO: add support for param combos expand iteration combos before square nesting
        # TODO: if self.parameter_combo_list: self.make_combo_iter(combo)
        error = None
        if self.parameter_list_list is None:
            self.parameter_list_list = [[]]
        for parameter_list in self.parameter_list_list:
            # run each iteration
            if parameter_list:
                self.result.test_step("Iteration for parameters: %s" % str(parameter_list))

            self.shared_data.initiates_done = False
            try:
                self.initiate(*parameter_list)
                # Run any nested tests, provided initiate completed successfully
                for nested_test in self.nested_tests:
                    # Resources and options are shared
                    nested_test.resources = self.resources
                    nested_test.options = self.options
                    temp_error = nested_test.run_test()
                    # Pass any errors back up the call chain
                    if temp_error is not None:
                        error = temp_error

                # Signal all initiates executed
                if not self.nested_tests == []:
                    self.shared_data.initiates_done = True

                try:
                    self.complete(*parameter_list)
                # pylint: disable=broad-except
                # Catch any abort and record this in results
                except Exception as temp_error:
                    error = temp_error
                    self.result.assert_outcome(html=False)
                    self.result.test_summary(html=False)
                    self.report_abort("%s" % (get_stack_trace(self.full_stack_trace)))

            # pylint: disable=broad-except
            # Catch any abort and record this in results
            except Exception as temp_error:
                error = temp_error
                self.result.assert_outcome(html=False)
                self.result.test_summary(html=False)
                self.report_abort("%s" % (get_stack_trace(self.full_stack_trace)))
            self.iteration_count += 1
        return error

    @timeout(10*60)
    def report_result(self):
        """
        Notifies the underlying test system of the test results.

        Return:
            int: a code for the overall outcome (0 for :obj:`PASS`, 1 for
                :obj:`FAIL and 2 for :obj:`ABORT`).
        """
        result_state = self.result.get_overall_outcome()
        reason = self.result.assert_outcome(html=False)
        test_summary = self.result.test_summary(html=False)
        log = logging.getLogger("TestResultsSummary")

        self.set_log_level(logging.INFO)
        log.info("===================================================")
        log.info("TEST RESULTS SUMMARY: \n%s", test_summary)
        log.info("===================================================")
        log = logging.getLogger("Assertions Summary")
        log.info("ASSERTIONS SUMMARY: \n%s", reason)
        # Return log level to info, always want overall outcome
        log.info("===================================================")
        log.info("OVERALL OUTCOME: %s", self.result.get_overall_outcome())
        log.info("===================================================")
        if result_state == "PASS":
            output_value = 0
        elif result_state == "FAIL":
            # Fail is assigned value 2, to allow differentiation between fail and fail
            # to compile, as failure to compile gives value 1 which is an abort
            output_value = 2
        else:
            # abort
            output_value = 1
        result = -1
        if self.test_system is not None:
            if result_state == "PASS":
                result = self.test_system.test_pass(reason)
            elif result_state == "FAIL":
                result = self.test_system.test_fail(reason)
            else:
                result = self.test_system.test_abort(reason)
        else:
            if result_state == "PASS":
                result = 0
            elif result_state == "FAIL":
                result = 1
            else:
                result = 2

        if self.allow_base_to_exit:
            self.log.info(self.result.get_overall_outcome())
            sys.exit(output_value)
        else:
            return result

    def report_abort(self, aborted):
        """
        Reports a test abortion.

        Args:
            aborted (:obj:`str`): an abort message.
        """
        self.result.record_abort(aborted)

        if self.test_system is None:
            # No test system provided
            self.log.critical("TEST ABORTED: %s", aborted)

    def run(self):
        """
        Executes the test and all its nested tests.

        Note:
            This is the main entry-point for test execution.

        Warning:
            Sub-classes should **not** override that method.
        """
        try:
            self.run_setup()
            self.run_test()

        # pylint: disable=broad-except
        # Catch any aborted tests and record abort in results
        except (Exception, KeyboardInterrupt, SystemExit):
            # All exceptions including kill signal will cause test abortion
            stack_trace = get_stack_trace(self.full_stack_trace)
            self.result.assert_outcome(html=False)
            self.result.test_summary(html=False)
            self.report_abort("%s" % stack_trace)
        finally:
            # Run teardown to cleanup before exiting from the test run
            try:
                self.run_teardown()

            # pylint: disable=broad-except
            # Catch any exceptions during cleanup (example: keyboard interrupt)
            except Exception:
                stack_trace = get_stack_trace(self.full_stack_trace)
                self.log.warning("teardown failed - %s", stack_trace)

        # Free all resources
        self._free_resources()
        self.log.info("All resources stopped")

        # cleanup log handlers
        self.log.handlers = []

        return self.report_result(), self.result

    def _free_resources(self):
        """
        Free all claimed resources.
        """
        self.log.info("Releasing all the resources")
        for resource in self.resources.values():
            try:
                resource.stop()
                resource.resource_base.stop()
            except EOFError:
                self.log.info("Connection for resource %s is already closed", resource.tag)
            except TestHeadClientError:
                self.log.warning("Something went wrong when releasing resource %s", resource.tag)
                self.log.warning("Stacktrace:%s", get_stack_trace(self.full_stack_trace))

        if self.test_system:
            self.test_system.shutdown()
