from __future__ import annotations

import csv
import inspect
import json
import logging
import os
import re
import sys
import textwrap
import traceback
import types
from abc import ABCMeta
from dataclasses import dataclass, field
from enum import Enum, EnumMeta
from importlib import import_module
from inspect import isclass
from pathlib import Path
from types import ModuleType
from typing import Dict, List, Tuple, Any, Set, Callable, Type, TypeVar, Iterator

import tabulate

import cl_test_station
import cl_test_station.utilities.iter_priority as iter_priority
import yaml
from cl_test_station.pyro_support.pyro_receiver import PyroReceiver
from cl_test_station.register_map.field import Field
from cl_test_station.utilities.cl_yaml_loader import load_and_expand_yaml
from cl_test_station.utilities.dummy_object import DummyObject
from cl_test_station.utilities.reusables import get_attr_safe, get_user_log_path, import_class_from_path
from cl_test_station.utilities.reusables import read_enum_value, read_int_value, read_bool_value
from cl_test_station.utilities.ts_logging import TsLoggingAdapter, add_file_handler, add_stream_handler


TsoType = TypeVar("TsoType")


class TestStationObjectConfigError(Exception):
    pass


class InvalidAccessError(Exception):
    """**Raises the following error: 'Cannot access {ref_name} due to error in its construction: {trace}'**"""
    def __init__(self, ref_name, trace=''):
        self.ref_name = ref_name
        self.trace = trace.replace('most recent call last', 'error during construction')
        super().__init__('Cannot access %s due to error in its construction\n\n%s' % (ref_name, trace))


class InvalidTsobject(DummyObject):
    """Raises error for Invalid Tso Objects"""
    def __init__(self, ref_name, trace, logger):
        self.ref_name = ref_name
        self.trace = trace
        self.log = logger  # type: TsLoggingAdapter
        self.has_warned = False

    def __getattribute__(self, item):
        return object.__getattribute__(self, item)

    def __setattr__(self, key, value):
        return object.__setattr__(self, key, value)

    def __getattr__(self, item):
        try:
            return self.__getattribute__(item)
        except AttributeError:
            pass
        object.__getattribute__(self, 'log').error("Cannot access %s because %s failed to construct" % (item, self.ref_name))
        raise InvalidAccessError(self.ref_name, self.trace)


class TsoTags(Enum):
    """Base Enum for TsoField tags"""


@dataclass
class TsoField:
    """**Format for TsoFields.**"""
    name: str = field(init=False)
    src_class: str = field(init=False)
    ftype: Type
    required: bool = True
    default: Any = None
    default_factory: Callable = None
    desc: str = ''
    tag: TsoTags = None
    cast_type: Type = field(default=None, repr=False)
    formatter: Callable = field(default=None, init=False, repr=False)

    def __post_init__(self):
        if self.cast_type is None:
            self.cast_type = self.ftype
        if self.cast_type is int:
            self.formatter = read_int_value
        elif self.cast_type is bool:
            self.formatter = read_bool_value
        elif isinstance(self.cast_type, EnumMeta):
            self.formatter = lambda string, enum_cls=self.cast_type: read_enum_value(string, enum_cls)
        else:
            self.formatter = self.cast_type


def exclude_tags(*tags: TsoTags):
    """**TSO Class decorator that allows field exclusion via tags.**"""

    def decorator(cls: TestStationObject):
        cls.remove_tags(*tags)
        return cls
    return decorator


def exclude_fields(*fields: str):
    """**TSO Class decorator that allows field exclusion via field names.**"""

    def decorator(cls: TestStationObject):
        cls.remove_fields(*fields)
        return cls

    return decorator


class TsoMeta(ABCMeta):
    """**Gets the parent fields, find field definitions, and then adds to list in sorted fields.**"""
    def __init__(cls, *args, **kwargs):
        super().__init__(*args, **kwargs)
        cls.class_fields = {}
        # Get parent fields
        for parent in [c for c in cls.__bases__ if hasattr(c, 'class_fields')]:
            cls.class_fields.update({f.name: f for f in parent.class_fields})
        # Find field definitions and add to list
        for name, field in cls.__dict__.items():
            if isinstance(field, TsoField):
                field.__dict__['name'] = name
                field.__dict__['src_class'] = cls.__name__
                setattr(cls, name, field.default)
                cls.class_fields[name] = field
        # Sort Fields by required and then alphabetical
        cls.class_fields = sorted(cls.class_fields.values(), key=lambda field: (not field.required, field.src_class,
                                                                                field.name))

    def __instancecheck__(self, instance):
        if isinstance(instance, PyroReceiver):  # Need to check class_type
            if hasattr(instance, 'class_type') and hasattr(instance, 'get_mro_names'):
                return self.__name__ in instance.get_mro_names()  # __name__ is the name of the actual driver class
            else:
                return super().__instancecheck__(instance)  # Use python's implementation otherwise
        return super().__instancecheck__(instance)


class TestStationObject(metaclass=TsoMeta):
    """**Toolbox for all the TSO Field functions.**"""
    class_fields: Set[TsoField] = set()
    has_dynamic_attrs = False  # Flag to indicate if this class has dynamic attributes
    # TSO's will be grouped when calling post_* methods, in order from increasing group
    _post_initialize_group: int = iter_priority.NORMAL
    _post_construct_group: int = iter_priority.NORMAL
    # Fields
    config_file: str = TsoField(ftype=str, required=False,
                                desc="Path to external config YAML file to use for construction")
    config_files: List[str] = TsoField(ftype=list, required=False,
                                       desc="List of paths to external config YAML files to use for construction")

    @classmethod
    def get_class_fields(cls, only_required=False):
        return [f for f in cls.class_fields if (not only_required or f.required)]

    @classmethod
    def remove_tags(cls, *tags: TsoTags):
        """
        Removes all TsoFields that belong to each tag parameter given

        :param tags: All TsoTags that are to be removed
        :type tags: TsoTags
        :return: None
        :rtype: None
        """
        for tag in tags:
            for field in list(cls.class_fields):
                if field.tag is tag:
                    cls.class_fields.remove(field)

    @classmethod
    def remove_fields(cls, *fields: str):
        """
        Removes all TsoFields whose name matches fields names given

        :param fields: All field names that are to be removed
        :type fields: str
        :return: None
        :rtype: None
        """
        for field_name in fields:
            for field in list(cls.class_fields):
                if field.name == field_name:
                    cls.class_fields.remove(field)

    @classmethod
    def __gen_class_fields_table(cls, only_required: bool = False) -> Tuple[List[str], List[List[str]]]:
        """
        Generates table headers and rows for all TsoFields

        :param only_required: When True, only prints fields that are required
        :type only_required: bool
        :return: Tuple where the 1st value is a list of header names, and the second is a list of rows, where each
                 row is a list of strings containing field data.
        :rtype: tuple
        """
        fields = cls.get_class_fields(only_required)
        header = ['Name', 'Class', 'Type', 'Required', 'Default', 'Description']
        rows = [[f.name, f.src_class, f.ftype.__name__, f.required, f.default_factory() if f.default_factory else f.default, f.desc] for f in fields]
        return header, rows

    @classmethod
    def get_class_fields_table(cls, only_required: bool = False) -> str:
        """
        Generates tabulated string from class fields and returns it.

        :param only_required: When True, only prints fields that are required
        :type only_required: bool
        :return: Tabulate string output
        :rtype: str
        """
        header, rows = cls.__gen_class_fields_table(only_required=only_required)
        return tabulate.tabulate(rows, headers=header, disable_numparse=True)

    @classmethod
    def dump_class_fields(cls, only_required: bool = False):
        """
        Uses tabulate module to print out table of TsoField information

        :param only_required: When True, only prints fields that are required
        :type only_required: bool
        :return: None
        :rtype: None
        """
        print(cls.get_class_fields_table(only_required=only_required))

    @classmethod
    def dump_class_fields_csv(cls, file_path: str, only_required: bool = False):
        """
        Writes TsoField information to a csv file

        :param file_path: Path to csv file
        :type file_path: str
        :param only_required: When True, only prints fields that are required
        :type only_required: bool
        :return: None
        :rtype: None
        """
        header, rows = cls.__gen_class_fields_table(only_required=only_required)
        with open(file_path, 'w', encoding='UTF-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(header)
            writer.writerows(rows)

    def __init__(self, container=None, excluded_classes=None, ref_name: str = None,
                 preloaded_classes=None, logger=None, log_level=None, **kwargs):

        self.container = container  # type: TestStationObject
        self.excluded_classes = excluded_classes
        self.ref_name = ref_name

        # Class references passed in from container
        # if preloaded_classes is None:
        #     self.global_classes = {}
        # else:
        #     self.global_classes = preloaded_classes

        resources = self.container.resources if self.container is not None else None
        self.log = self.get_ts_logger(logger, resources)  # type: TsLoggingAdapter
        log_level = log_level if log_level else self.log.getEffectiveLevel()
        self.log.setLevel(log_level)

        self.valid_config_files = {'.yml': self.load_yaml}

        self.resources = {}  # Dictionary of all resources created for fast indexing
        self.valid_configs = []  # Used to check the valid configs for each class type

        # Error log for tracking import errors. Will be based on operating system.
        # Todo: merge this in with test station main log file whenever that gets implemented
        if sys.platform == 'win32':
            self.import_error_log = os.environ['USERPROFILE'] + '/python/cl_test_station/import_error_log.txt'
        else:
            self.import_error_log = os.path.dirname(cl_test_station.__file__) + '/utilities/import_error_log.txt'

        # todo: See if there is a better more metaclass-contained way of doing factories
        for field in self.get_class_fields():
            if field.default_factory is not None:
                setattr(self, field.name, field.default_factory())

         # Add kwargs to config
        self.config = kwargs

        # Set attributes for all non TSO keyword arguments. Format fields to specified type.
        field_map: Dict[str, TsoField] = {f.name: f for f in self.get_class_fields()}
        for name, value in self.config.items():
            # Skip any nested TSO definitions
            if type(value) is dict and 'class_type' in value:
                continue
            # Expand ENV variables for all strings
            if type(value) is str:
                # Skip ENV variables that are empty to preserve defaults
                if value.startswith('$') and not os.path.expandvars(value) and name in field_map:
                    continue
                value = os.path.expandvars(value)

            # Format TSO fields if input type is different from ftype
            if name in field_map:
                field = field_map[name]
                if value is not None and not isinstance(value, field.cast_type):  # Format input value
                    self.log.debug(f"Formatting field '{name}' (type {type(value)}) using {field.formatter}")
                    try:
                        value = field.formatter(value)
                    except Exception as fmt_err:
                        self.log.error(f"Failed to format field '{name} (received {fmt_err.__class__.__name__})'."
                                       f" Value '{value}' will be of type str")
                        raise fmt_err
            # Update config dictionary and instance attribute with new value
            self.config[name] = value
            setattr(self, name, value)

        # Expand config file references
        while self.config_file or self.config_files:
            config_files = []
            if self.config_file:
                config_files.append(self.config_file)
                self.config.pop('config_file')
            if self.config_files:
                config_files.extend(self.config_files)
                self.config.pop('config_files')
            for config_file in config_files:
               self.config.update(load_and_expand_yaml(config_file))
            # Update fields to allow for nested config files
            self.config_file = self.config.get('config_file', None)
            self.config_files = self.config.get('config_files', None)

        # Set class_type using module anc class name
        self.class_type = self.__module__ + '.' + self.__class__.__name__

    def __getattribute__(self, item):
        result = object.__getattribute__(self, item)
        if isinstance(result, InvalidTsobject) and not result.has_warned:
            object.__getattribute__(self, 'log').warning("Accessing unconstructed object '%s', it will NOT function correctly" % item)
            result.has_warned = True
        return result

    def __iter__(self) -> Iterator[Tuple[str, 'TestStationObject']]:
        for name, attr in self.resources.items():
            if name == 'container':
                continue
            if isinstance(attr, TestStationObject):
                yield attr.ref_name, attr
                yield from attr.__iter__()

    def get_mro_names(self):
        return [c.__name__ for c in self.__class__.__mro__]

    def configure(self, config, *args, construct=True, **kwargs):
        """
        If config file is valid, then constructs the client side system. This will construct anything that is not a
        TestStationServer. It will attempt to check if a TestStationServer is running and get resources from the server.

        :param config: yml file
        :type config: str or dict
        :param args:
        :type args:
        :param construct:
        :type construct:
        :param kwargs:
        :type kwargs:
        :return:
        """
        # config attribute is set in __init__ instead of this method, which will be removed in PLATDEV-1078
        # if isinstance(config, type({})):
        #     self.config = config
        if type(config) == str:
            if Path(config).suffix == '.yml':
                with open(config, 'r') as yml_file:
                    self.config = yaml.load(yml_file, Loader=yaml.FullLoader)
        # Check if config_file is in the dictionary
        # todo: Integrate this with reusables, check if the whole 'valid_config_files' system can go since its complicated
        if "config_file" in self.config.keys():
            config_file = os.path.expandvars(self.config['config_file'])
            if Path(config_file).suffix in self.valid_config_files.keys():
                load_func = self.valid_config_files[Path(config_file).suffix]
                try:
                    extended_cfg = load_func(config_file)
                except FileNotFoundError:
                    if 'base_config_file' in self.config.keys():
                        with open(os.path.expandvars('$CONFIGS/station_configs/instrument_config.yml'),
                                  'r') as instr_yml:
                            common_config = yaml.load(instr_yml, Loader=yaml.FullLoader)
                        with open(os.path.expandvars('$CONFIGS/station_configs/instrument_config_$STATION_NAME.yml'),
                                  'w') as file:
                            yaml.dump(common_config, file, sort_keys=False)
                        extended_cfg = load_func(config_file)
                    else:
                        raise Exception("Both base_config_file and config_file are not found for class type '{}'".format(self.config['class_type']))
                if extended_cfg is not None:
                    self.config.update(extended_cfg)
        if construct:
            self.construct_objects(**kwargs)

    def get_invalid_configs(self):
        """
        Compares the config_keys to valid configs. If not a valid config, adds the config_key to invalid_configs.

        :return: invalid_configs
        """
        invalid_configs = []
        for config_key in self.config.keys():
            if config_key not in self.valid_configs:
                invalid_configs.append(config_key)
        return invalid_configs

    def construct_objects(self, *args, specific_class=None, **kwargs) -> Dict[str, object]:
        """
        Takes in an object dictionary and constructs a TestStation object.

        :param specific_class: class input to build only specific types of classes
        :type specific_class: class
        :return: Resource dictionary
        """
        local_resources = {}
        # Check that the config is a dictionary
        if isinstance(self.config, dict):
            for key in self.config:
                # If an object with this name already exists, it was previously constructed, so do not construct again
                sub_config = self.config[key]
                # self.config is most likely a dictionary of dictionaries. Check that the subconfig is a dictionary
                if isinstance(sub_config, dict) and 'class_type' in sub_config:
                    # If class_type is in the keys, this indicates a class object is being defined
                    class_type = os.path.expandvars(sub_config['class_type'])
                    # Try and import, otherwise through an error
                    try:
                        tso_cls = import_class_from_path(class_type)
                    except (AttributeError, ModuleNotFoundError):
                        raise ValueError(f"Cannot construct {key}, {class_type} neither preloaded or importable")
                    instantiate = True  # Flag to indicate that the class passes all conditions to instantiate
                    # Check if the class_type is in the list of classes to exclude
                    if self.excluded_classes is not None:
                        for excluded_class in self.excluded_classes:
                            if issubclass(tso_cls, excluded_class):
                                instantiate = False
                    # If a specific class is specified, check that 'class_type' is a subclass of the specific class
                    if specific_class is not None:
                        if not issubclass(tso_cls, specific_class):
                            instantiate = False
                    # Object creation if the previous cases hold true
                    if instantiate:
                        # instantiate the object by class type
                        # Construct the object here and pass in the global_attributes to the preloaded_classes
                        try:
                            # Pass in sub_config as kwargs, will become base attributes for new TSO
                            test_station_obj = tso_cls(self, ref_name=key, logger=self.log,
                                                       log_level=self.log.getEffectiveLevel(), **sub_config)
                            self.__setattr__(key, test_station_obj)
                            self.resources.update({key: test_station_obj})
                            test_station_obj.check_fields()
                            test_station_obj.configure(test_station_obj.config)
                        except Exception:
                            self.log.exception(f"Failed to construct {key} (class {tso_cls.__name__})")
                            self.__setattr__(key, InvalidTsobject(key, traceback.format_exc(), self.log))

        # Return the local_resources to be enable any calling function quick access to the objects created
        # without having to search through the self.resources dictionary
        # self.resources.update(local_resources)
        return self.resources

    def post_construct_system(self):
        """
        Perform any operations that requires all objects within the test station to be constructed

        :return: None
        """

    def initialize(self, standalone=False, **kwargs):
        """
        Base initialize implementation which initializes all parents of the given object

        :param standalone: call initialize on only this object (Default: False)
        :type standalone: bool
        :param kwargs: pass through keyword arguments
        :type kwargs: Any
        :return: None
        :rtype: None
        """
        if self.container is not None and not standalone:
            self.container.initialize()
        self.log.info("Initializing %s <class: %s, module: %s>" % (self.ref_name, self.__class__.__name__,
                                                                   self.__class__.__module__))

    def post_system_initialize(self, **kwargs):
        """
        Operations that occur for a particular TSO after every TSO has been initialized

        :param kwargs: pass through keyword arguments
        :type kwargs: Any
        :return: None
        :rtype: None
        """

    def shutdown(self, standalone=False, **kwargs):
        """
        Base shutdown implementation which shutdowns all resources below the given object

        :param standalone: call shutdown on only this object (Default: False)
        :type standalone: bool
        :param kwargs: pass through keyword arguments
        :type kwargs: Any
        :return: None
        :rtype: None
        """
        if not standalone:
            for ref_name, resource in self.resources.items():
                if isinstance(resource, TestStationObject):
                    resource.shutdown()
        self.log.info("Shutting down %s <class: %s, module: %s>" % (self.ref_name, self.__class__.__name__,
                                                                    self.__class__.__module__))

    def check_fields(self, config=None):
        """
        Checks the fields, for any missing required fields.

        :param config:
        :return:
        """
        missing = []
        fields = self.__class__.get_class_fields(only_required=True)
        for field in fields:
            if field.required and field.name not in self.config.keys():
                missing.append(field)
        if missing:
            fields = self.get_class_fields(only_required=True)
            rows = [[f.name, f.ftype.__name__, f.required, f.default, f.desc] for f in fields]
            req_fields = tabulate.tabulate(rows, headers=['Name', 'Type', 'Required', 'Default', 'Description'], disable_numparse=True)
            missing_fields = '", "'.join([f.name for f in missing])
            raise Exception(f'Field{"s" if len(missing) > 1 else ""} "{missing_fields}" missing for definition '
                            f'of {self.ref_name}.\nCheck configuration file to ensure all required fields '
                            f'are populated\nRequired fields for {self.ref_name} are:\n\n{req_fields}')

    def load_paths(self):
        """
        Generates dictionary of {class_name: class} for all python classes in this package's directory and all
        subdirectories

        :return: Dictionary of all class references
        """
        sys.path.append(os.path.expandvars('$PYTHONPATH'))
        classes = {}
        # The top level should clear the import error log, otherwise just append the existing log file
        if self.container is None and os.path.exists(self.import_error_log):  # Top level
            os.remove(self.import_error_log)
        if self.container is None and not os.path.exists(str(Path(self.import_error_log).parent)):
            os.makedirs(str(Path(self.import_error_log).parent))

        paths_to_walk = [(str(Path(cl_test_station.__file__).resolve().parent), cl_test_station.__name__)]

        # Iterate through all paths
        for rootdir, prefix in paths_to_walk:
            classes.update(self.load_classes_from_path(rootdir, prefix))
        return classes

    @staticmethod
    def create_path(path: str):
        """
        Takes in the root path and returns a tuple that represents the directory to import from and the prefix for
        the import

        :param path: root directory to extract information from
        :type path: str
        :return: (root_dir, prefix)
        :rtype: tuple
        """
        # Get base directory relative to project root
        relative_path = os.path.normpath(os.path.relpath(os.path.expandvars(path),
                                                         start=os.path.expandvars('$PROJECT_ROOT')))
        # Convert relative path to dot structure for importing
        dot_path = ''
        for directory in relative_path.split('\\' if sys.platform == 'win32' else '/'):
            dot_path += directory + '.'
        return os.path.expandvars(path), dot_path[:-1]

    def load_classes_from_module(self, module):
        """
        Returns dictionary of classes in module. Does not search for submodules

        :param module: module name of type String or preloaded module of type ModuleType
        :return: {class name: class}
        :rtype: dict or form
        """
        if type(module) is str:
            try:
                module = import_module(module)
            except ModuleNotFoundError:
                self.log.warning(f"Could not import module '{module}', skipping")
        if not isinstance(module, ModuleType):
            raise ValueError("module must be str or ModuleType")
        classes = {}
        for attr_name in dir(module):
            if attr_name.startswith('__'):  # Skip internals
                continue
            attr = getattr(module, attr_name)
            if isclass(attr):  # Test if attribute is a Class
                classes[attr_name] = attr  # Add class to return dictionary
        return classes

    def load_classes_from_path(self, rootdir, prefix, base_cls=None):
        """
        Recursive helper function that walks through all subdirectories to file classes

        :param rootdir: starting directory of recursive search
        :type rootdir: str
        :param prefix: dot path representing import path to starting module
        :type prefix: str
        :param base_cls:
        :type base_cls:
        :return: dictionary of all classes in given directory of format: {class_name: class}
        :rtype: dict
        """
        sys.path.append(rootdir)
        classes = {}
        for item in os.scandir(rootdir):
            if item.is_dir():  # Load this directory
                classes.update(self.load_classes_from_path(rootdir + '/' + item.name, prefix + '.' + item.name, base_cls))
            elif item.is_file() and os.path.splitext(item.name)[1] == '.py' and '__init__.py' not in item.name:
                # find all classes in this file with current prefix
                try:
                    module = import_module(prefix + '.' + item.name[:-3])
                except Exception:
                    # Bad import, need to log the error and continue
                    trace = traceback.format_exc()
                    # Open bad file to get the class names
                    with open(rootdir + '/' + item.name, 'r', encoding='utf-8') as f:
                        bad_classes = re.findall(r'\nclass (\w+).*:\n', f.read()) # this re finds all class definitions
                    with open(self.import_error_log, 'a+') as f:
                        # Log bad import entry, containing list of classes in the file and the traceback
                        f.write('==========================================================================\n')
                        f.write('Could not import %s, skipping\n' % bad_classes)
                        f.write('\n' + trace + '\n\n')
                        f.write('==========================================================================\n')
                    self.log.warning("Could not import module '%s', skipping" % (prefix + '.' + item.name[:-3]))
                    continue
                for name, cls in inspect.getmembers(module, inspect.isclass):  # Get only classes from module
                    if cls.__module__ == module.__name__:  # Class is defined in the module
                        if base_cls is None or issubclass(cls, base_cls):  # Add to return dictionary
                            classes[name] = cls
                # for attribute_name in dir(module):
                #     attribute = getattr(module, attribute_name)
                #     if isclass(attribute) and (base_cls is None or issubclass(attribute, base_cls)):
                #         classes[attribute_name] = attribute
        return classes

    def find_top_level(self):
        """
        Finds the top level of module.

        :return: Returns the top level
        :rtype: TestStation
        """
        attribute = import_class_from_path("cl_test_station.test_station.TestStation")
        temp = self
        while not ((temp is None) or isinstance(temp, attribute)):
            temp = temp.__getattribute__("container")
        return temp

    def find_container(self, class_type):
        """
        Searches through the object's hierarchy of containers to see if it is contained inside a particular class type

        :param class_type: specific class type to search for
        :type class_type: class
        :return:
        """
        if self.container is not None:
            if isinstance(self.container, class_type):
                return self.container
            else:
                return self.container.find_container(class_type)
        return None

    def find_resource(self, resource_name): # todo: return dict with ts_path: reference -- support multiple finds
        """
        Place Holder

        :param resource_name:
        :return:
        """
        found = []
        for name, tso in self:
            if name == resource_name:
                found.append((tso.path, tso))
        for attr in self.__dict__.values():
            if isinstance(attr, PyroReceiver) and attr.my_name == resource_name:
                found.append((resource_name, attr))
        return found if found else None

    def find_all(self, class_type: Type[TsoType], start_from_top: bool = False) -> List[Tuple[str, TsoType]]:
        """
        Searches all TSOs under self (or top level if start_from_top is True) for instances of 'class_type' and
        returns all found instances.

        :param class_type: Subclass of TSO to search for. eg. Component will find all components, DUTs, FPGAs, etc.
        :type class_type: TestStationObject
        :param start_from_top: When true, starts search at the top level TSO (TestStation)
        :type start_from_top: bool
        :return: List of Tuples containing the TSO path as a string and the TSO object reference
        :rtype: List[Tuple[str, TestStationObject]]
        """
        if not issubclass(class_type, TestStationObject):
            raise TypeError(f"class_type must be a subclass of TestStationObject, received: {class_type.__name__}")
        found = []
        for ref_name, tso in self.find_top_level() if start_from_top else self:
            if isinstance(tso, class_type):
                found.append((tso.path, tso))
        return found

    def resolve_path(self, path: str, start_from_top: bool = True) -> Any:
        """
        Takes a period-separated path of an object in the TestStation and returns a reference to that object.
        Path can either include the test_station's ref name, or it can be omitted.

        :param path: Dot path eg. test_station.board.component
        :type path: str
        :param start_from_top: Starts the search from the top level test station
        :type start_from_top: bool
        :return: Object reference
        :rtype: Any
        """
        ref_list = path.split('.')
        if start_from_top:
            attr = self.find_top_level()
        else:
            attr = self
        try:
            for ref_name in (ref_list[1:] if attr.ref_name == ref_list[0] else ref_list):
                attr = getattr(attr, ref_name)
            return attr
        except AttributeError:
            return None

    def __contains__(self, item):
        ref_name = item.ref_name if isinstance(item, TestStationObject) else item
        return self.find_resource(ref_name) is not None

    @staticmethod
    def load_yaml(path):
        """
        Place Holder

        :param path:
        :return:
        """
        config = {}
        with open(path, 'r') as yml_file:
            config = yaml.load(yml_file, Loader=yaml.FullLoader)
        return config

    def find_sub_config(self, top_level_config, resource_name=None, resource_class=None):
        """
        Place Holder

        :param top_level_config:
        :param resource_name:
        :param resource_class:
        :return:
        """
        for key in top_level_config:
            sub_config = top_level_config[key]
            if isinstance(sub_config, dict):
                result = None
                if resource_name is not None and resource_class is None:
                    if key == resource_name:
                        return sub_config
                    else:
                        result = self.find_sub_config(sub_config, resource_name)
                elif resource_name is None and resource_class is not None:
                    if 'class_type' in sub_config:
                        if sub_config['class_type'] == resource_class:
                            return sub_config
                        else:
                            result = self.find_sub_config(sub_config, resource_class=resource_class)
                elif resource_name is not None and resource_class is not None:
                    if 'class_type' in sub_config:
                        if sub_config['class_type'] == resource_class and key == resource_name:
                            return sub_config
                        else:
                            result = self.find_sub_config(sub_config, resource_name, resource_class)
                if result:
                    return result
        return None

    def serialize(self, top: bool = False, exclude_classes: List[str] = None, file_path: str = None,
                  compress: bool = True) -> Dict[str, Any]:
        """
        Function to serialize a test station object, flattening its nested object hierarchy into a dictionary

        **Note:** Will serialize all test station objects and peripheral/registers/fields but IGNORE flattened fields

        :param top: When true, will add TestStation class to 'test_station' key
        :type top: bool
        :param exclude_classes: List of strings containing classes to ignore in serialization
        :type exclude_classes: List[str]
        :param file_path: Optional path of file to dump serialized json data
        :type file_path: str
        :param compress: When True, the serialized data will be minified and compressed to reduce file/dictionary size
        :type compress: bool
        :return: Dictionary containing serialized TestStationObject
        :rtype: Dict **[str, Any]**
        """
        if exclude_classes is None:
            exclude_classes = []
        exclude_classes.extend(['Rail', 'RailContainer', 'RailReference', 'ValDBTool', 'ValDBs', 'StudioLinkAdapter'])  # todo: Fix rail serialization
        # Get base config that mirrors YAML (includes config_file extensions)
        base_dict = self.config.copy()
        for name in self.config.keys():
            if type(base_dict[name]) is dict and 'class_type' in base_dict[name]:  # This is a TSO, call its serialize()
                # Update raw config with custom serialized config
                if name in self.resources and base_dict[name]['class_type'].rpartition('.')[2] not in exclude_classes:
                    base_dict[name] = self.resources[name].serialize(top=False, exclude_classes=exclude_classes,
                                                                     file_path=file_path, compress=compress)
                else:
                    base_dict.pop(name)
        if top:
            base_dict = {self.ref_name: base_dict}
            if file_path is not None:
                if compress:
                    json_string = json.dumps(base_dict)
                else:
                    json_string = json.dumps(base_dict, indent=4)
                with open(os.path.expandvars(file_path), "w") as json_file:
                    json_file.write(json_string)
        return base_dict

    def get_required_packages(self):
        """
        Looks through hierarchy for any classes used that are not in cl_test_station

        :return: set of preloaded modules that are required to construct the ts_obj and everything it contains
        """
        self.log.warning("This function is deprecated. Will be removed soon")
        return set()

    def gen_pyi(self, indent: int = 0, top: bool = False) -> Tuple[str, Set[Tuple[str, str]]]:
        """
        Generates pyi stub file contents for dynamic attributes of Test Station Object

        :param indent: Tab-level that mirrors object hierarchy.
        :type indent: int
        :param top: Flag for top level to use Class name for pyi recognition.
        :type top: bool
        :return: File contents for .pyi file and import set for top of file.
        :rtype: Tuple[str, Set[Tuple[str, str]]]
        """
        old_level = self.log.getEffectiveLevel()
        self.log.setLevel(self.log.ERROR)
        imports = set()
        tab = '    '
        module, sep, cls = self.class_type.rpartition('.')  # Get module and class information
        bases = ', '.join([b.__name__ for b in self.__class__.__bases__])
        for base in self.__class__.__bases__:
            imports.add((base.__module__, base.__name__))
        if top:  # Create empty class definition
            pyi_contents = ['import cl_test_station\nfrom typing import *\n']
            pyi_contents.extend([tab * indent, 'class %s(%s):\n' % (cls, bases)])
        else:  # Import class and create child class definition
            imports.add((module, cls))  # Add import information
            pyi_contents = []
            pyi_contents.extend([tab*indent, 'class %s(%s):\n' % (self.ref_name, cls)])
        function_set = set()
        for base in self.__class__.__mro__[1:-1]:
            for item in base.__dict__.values():
                if inspect.isfunction(item):
                    function_set.add(item)
        # Create container list to check for backwards references
        tso = self
        container_list = []
        while tso.container:
            container_list.append(tso.container)
            tso = tso.container
        for name in dir(self):
            value = get_attr_safe(self, name)
            # Ignore internal attrs and references to containers
            if name.startswith('_'):
                continue
            try:  # Some objects can throw exceptions when checking __eq__
                if value in container_list:
                    continue
            except TypeError:  # Insert basic stub into contents
                self.log.dev(f"Error handling attribute {name}:\n{traceback.format_exc()}")
                if hasattr(value.__class__, '__name__') and hasattr(value.__class__, '__module__'):
                    pyi_contents.extend([tab * (indent + 1), name, ':', value.__class__.__name__, '\n'])
                    imports.add((value.__class__.__module__, value.__class__.__name__))
                continue
            # This attribute needs a stub entry, check type/format
            if inspect.isfunction(value):
                if value in function_set:
                    continue
                func_src = inspect.getsource(value)  # Get function source code
                for comment in re.findall('(\#(.*?))\n', func_src):  # Remove all comments from header lines
                    func_src = func_src.replace(comment[0], '')
                sig_str = re.search(r'((.|\n)+?):\s*\n', func_src).group().rstrip()
                sig_str += 'pass\n'
                sig_str = textwrap.dedent(sig_str)  # Removes highest indentation while maintaining structure
                sig = inspect.signature(value)
                for param_name, param in sig.parameters.items():  # Find any enums/special defaults that need to be imported
                    if param.annotation not in [inspect._empty, None] and param.annotation.__class__.__name__ not in types.__builtins__:
                        imports.add((param.annotation.__module__, param.annotation.__class__.__name__))
                    if param.default not in [inspect._empty, None] and param.default.__class__.__name__ not in types.__builtins__:
                        imports.add((param.default.__module__, param.default.__class__.__name__))
                pyi_contents.extend([tab*(indent + 1), sig_str])
            elif type(value) is property:  # Stub as attribute with return type hint
                sig = inspect.signature(value.fget)
                if hasattr(value.fget, 'pyi_safe') and value.fget.pyi_safe:
                    prop_value = value.fget(self)
                    ftype = prop_value.__class__.__name__
                    imports.add((prop_value.__class__.__module__, prop_value.__class__.__name__))
                else:
                    ftype = sig.return_annotation if sig.return_annotation is not inspect._empty else 'None'
                pyi_contents.extend([tab * (indent + 1), name, ':', str(ftype), '\n'])
            elif isinstance(value, (TestStationObject, PyroReceiver)) and hasattr(value, 'class_type'):
                # Check for dynamic registers or nested TSO's
                if (hasattr(value, 'has_dynamic_attrs') and value.has_dynamic_attrs) or (hasattr(value, 'resources') and value.resources):
                    # Get Pyi string and import data from nested TSO
                    self.log.setLevel(old_level)
                    new_pyi_string, new_imports = value.gen_pyi(indent=indent+1)
                    pyi_contents.extend(new_pyi_string)
                    imports.update(new_imports)
                    pyi_contents.extend([tab * (indent + 1), name, ':', value.ref_name, '\n'])
                else:  # Regular TSO at the end of hierarchy, just add short stub entry
                    module, sep, class_name = value.class_type.rpartition('.')
                    imports.add((module, class_name))
                    pyi_contents.extend([tab * (indent + 1), name, ':', class_name, '\n'])
            elif inspect.isclass(value):
                imports.add((value.__module__, value.__name__))
                pyi_contents.extend([tab * (indent + 1), name, ':', value.__name__, '\n'])
            elif hasattr(value.__class__, '__name__') and hasattr(value.__class__, '__module__'):
                # todo: Temp fix for flattened fields
                if type(value) is Field:
                    continue
                pyi_contents.extend([tab * (indent + 1), name, ':', value.__class__.__name__, '\n'])
                imports.add((value.__class__.__module__, value.__class__.__name__))
        self.log.setLevel(old_level)
        return ''.join(pyi_contents), imports

    def generate_id(self, level: int = 1, recursive: bool = True, dbg_dict: Dict = None) -> int:
        """
        Uses ref_name and the class type to generate an ID unique to a specific test station configuration

        :param level: level of recursion that affects multiplier of ID sum
        :type level: int
        :param recursive: Recurse through all contained TestStationObjects and add to sum
        :type recursive: bool
        :param dbg_dict: If a dictionary reference is passed in, it will be filled with itemized account of all objects
            and their respective ID values
        :type dbg_dict: Dict
        :return: ID value
        :rtype: int
        """
        # Get char sum of ts_obj
        str_sum = sum(bytearray(self.ref_name+self.class_type, 'utf-8'))*(2**level)
        self.log.dev("Ref_name: %s, class_type: %s" % (self.ref_name, self.class_type))
        self.log.dev("    Sum of name, class_type: %d" % str_sum)
        if type(dbg_dict) is dict:
            dbg_dict['name sum'] = str_sum
        # Get sum of source code
        filename = inspect.getfile(self.__class__)

        with open(filename, 'r', encoding='utf-8') as f:
            source_code = f.read()
        source_sum = sum(bytearray(source_code, 'utf-8'))
        self.log.dev("    Sum of source code: %d" % source_sum)
        if type(dbg_dict) is dict:
            dbg_dict['source sum'] = source_sum
        str_sum += source_sum
        if recursive:
            # Add sums of children
            for ref_name, resource in self.resources.items():
                if isinstance(resource, TestStationObject):
                    if type(dbg_dict) is dict:
                        dbg_dict[resource.ref_name] = {}
                        d = dbg_dict[resource.ref_name]
                    else:
                        d = dbg_dict
                    str_sum += resource.generate_id(level+1, recursive, d)
        self.log.dev(("  RUNNING TOTAL: %d  " % str_sum).center(80, '-'))
        return str_sum

    def get_ts_path(self) -> str:
        """
        Gets structural path of test station object, eg (test_station.board1.dut)

        :return: string
        """
        containers = []
        ts_obj = self
        while ts_obj.container is not None:
            containers.append(ts_obj.container.ref_name)
            ts_obj = ts_obj.container
        return '.'.join(list(reversed(containers))+[self.ref_name])

    @property
    def path(self) -> str:
        return self.get_ts_path()

    def get_ts_logger(self, logger, resources=None):
        """
        Place Holder

        :param logger:
        :param resources:
        :return:
        """
        filename = get_user_log_path('test_station_log.log')
        if logger is None:  # Grab cl_test_station logger and add handlers
            logger = logging.getLogger('cl_test_station')
            if logger.handlers == []:
                add_stream_handler(logger)
                add_file_handler(logger, filename)
        elif isinstance(logger, TsLoggingAdapter):  # log adapter is passed in from another TSO, use its internal logger
            logger = logger.logger
        else:  # External logger passed in, transfer handlers and add Filehandler and stdout handler
            ts_logger = logging.getLogger('cl_test_station')
            if isinstance(logger, logging.Logger):
                ts_logger.handlers.extend(logger.handlers)
            elif isinstance(logger, logging.LoggerAdapter):
                ts_logger.handlers.extend(logger.logger.handlers)
            add_stream_handler(ts_logger)
            add_file_handler(ts_logger, filename)
            logger = ts_logger
        logger.propagate = False  # Prevents double prints, cl_test_station uses custom color formatted stdout handler
        return TsLoggingAdapter(logger, self.get_ts_path(), resources)

    def update_pyi_file(self, pyi_content):
        """
        Place Holder

        :param pyi_content:
        :return:
        """
        pyi_file = inspect.getfile(self.__class__) + 'i'
        old_contents = ''
        if os.path.exists(pyi_file):  # Read to check for differences
            with open(pyi_file, 'r') as f:
                old_contents = f.read()
        if pyi_content != old_contents:  # Only overwrite if there's been changes to the pyi structure
            self.log.debug(f"Updating stub file: {os.path.basename(pyi_file)}")
            with open(pyi_file, 'w') as f:
                f.write(pyi_content)
        else:
            self.log.debug(f"Stub file for {self.ref_name} up to date")

    def _write_pyi_file(self, pyi_str: str, imports: Set[str, str]):
        write_lines = []
        # Write all import statements at the top of the file
        for module, cls_name in sorted(imports):
            write_lines.append(f"from {module} import {cls_name}")
        # Replace class name from ref_name (flat pyi) to actual class name (module pyi)
        pyi_str = pyi_str.replace(f"class {self.ref_name}", f"class {self.__class__.__name__}")
        # Create file content string
        write_lines.append(pyi_str)
        new_contents = '\n'.join(write_lines)
        # Attempt to update file with new contents
        self.update_pyi_file(new_contents)

    def _get_pyi_reference(self) -> Tuple[str, Set[str, str]]:
        # Do not need any extra content, gen_pyi() adds reference via ref_name
        pyi_str = ''
        # Import class as ref_name so that type hint reflects class's pyi file
        imports = {(self.__module__, f'{self.__class__.__name__} as {self.ref_name}')}
        return pyi_str, imports


def pyi_safe(func):
    """
    Decorator that tags properties that are safe to get during the .pyi generation phase. Useful for providing dynamic
    type hints in stub files
    """
    def inner(*args, **kwargs):
        return func(*args, **kwargs)
    inner.__signature__ = inspect.signature(func)
    inner.pyi_safe = True
    return inner


if __name__ == "__main__":
    from pathlib import Path
    import yaml

    os.environ['PACKAGE_ROOT'] = r'C:\validation\Projects\Mahoney\mahoney_test_env\src\cl-test-station'
    this_path = Path(__file__).resolve().parent
    test_yaml = this_path / 'example_yaml' / 'board_factory_unit_test.yml'
    extra_paths = [os.path.expandvars(r'$PACKAGE_ROOT\cl_test_station\board\test_input\test_peripherals')]
    # extra_paths.append(r'C:\validation\Projects\Mahoney\mahoney_test_env\src\cl-test-station\cl_test_station\board\ctrl_interface')

    with open(test_yaml, 'r') as yml_file:
        board_config = yaml.load(yml_file, Loader=yaml.FullLoader)

    test_station = TestStationObject(board_config, None, extra_paths)
    print(test_station)
