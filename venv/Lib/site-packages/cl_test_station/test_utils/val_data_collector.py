import pandas as pd
from cl_test_station.test_station_object import TestStationObject
from cl_test_station.board.board import Board
from cl_test_station.components.dut.dut import Dut


class ValDataCollector(TestStationObject):
    """Place Holder"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.val_data_logger = self.container.data_logger
        self.df_data_float = None
        self.df_data_string = None
        self.df_data_file = None
        self.df_data_sweep = None
        self.df_size_limit =  1000
        self.df_size = 0
        self.vcorner_str = None
        self.tcorner_str = None
        self.measurement_group = None
        self.measurement_group_desc = None
        self.ignore_data = 1
        # ToDo: Change from bay number to location string and update lab database accordingly
        self.bay_number = 5 # todo: change the default
        self.valdata_root_folder = None
        self.project_test_name = None
        self.enable_buffer = False

    def config_data_logging(
        self, file_or_database=0, filename_enable_timestamp=True, test_category_desc=None,
        test_table_name='validation', tcorner_str='ROOM', vcorner_str='TYP', ignore_data = 1, bay_number = 5,
        valdata_root_folder=None, project_test_name=None, measurement_group = None, measurement_group_desc = None
    ):
        """
        Place Holder

        :param file_or_database:
        :param filename_enable_timestamp:
        :param test_category_desc:
        :param test_table_name:
        :param tcorner_str:
        :param vcorner_str:
        :param ignore_data:
        :param bay_number:
        :param valdata_root_folder:
        :param project_test_name:
        :param measurement_group:
        :param measurement_group_desc:
        :return:
        """

        self.val_data_logger.select_test_table(test_table_name)
        tp_table_name = self.val_data_logger.db_logging_dict['params_table_name']
        self.tp_table = getattr(self.container.db_proj, tp_table_name)

        self.vcorner_str = vcorner_str
        self.tcorner_str = tcorner_str
        self.test_category_desc = test_category_desc
        self.ignore_data = ignore_data
        self.bay_number = bay_number
        self.file_or_database=file_or_database  # ToDo: switch to enum and rename to mode
        self.enable_buffer = file_or_database==0 #todo: future case of csv->db
        self.filename_enable_timestamp = filename_enable_timestamp
        self.valdata_root_folder = valdata_root_folder
        self.project_test_name = project_test_name
        if measurement_group is None:
            self.measurement_group = self.project_test_name
        else:
            self.measurement_group = measurement_group
        if measurement_group_desc is None:
            self.measurement_group_desc = self.project_test_name
        else:
            self.measurement_group_desc = measurement_group_desc
        return self.tp_table

    def table_to_dict(self, table_obj):
        """
        Returns a table object in dictionary format.

        :param table_obj: The table obj to format.
        :return: dict_table
        """
        cols = table_obj.columns.copy()
        cols.remove('id')
        vals = [getattr(self.tp_table, col) for col in cols]
        dict_table = dict(zip(cols, vals))
        return dict_table

    #todo: add log_float_data(self, ) and other
    def log_float_data(self, measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if self.enable_buffer: # self.enable_buffer = file_or_database==0 (0 for file)
            self.push_float_data_to_df(measurement_list, update_tp_table, tp_x)
        else:
            self.log_float_data_to_db(measurement_list, update_tp_table, tp_x)

    def log_sweep_data(self, sweep_data, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param sweep_data:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if self.enable_buffer: # self.enable_buffer = file_or_database==0 (0 for file)
            sweep_name = sweep_data.sweep_name
            series_list =sweep_data.series_list
            dut_id = sweep_data.dut_id
            self.push_sweep_data_to_df(sweep_name, series_list, update_tp_table, tp_x, dut_id)
        else:
            self.log_sweep_data_to_db(sweep_data, update_tp_table, tp_x)

    def log_file_data(self,  measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if self.enable_buffer: # self.enable_buffer = file_or_database==0 (0 for file)
            self.push_file_data_to_df(measurement_list, update_tp_table, tp_x)
        else:
            self.log_file_data_to_db(measurement_list, update_tp_table, tp_x)

    def log_string_data(self,  measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if self.enable_buffer: # self.enable_buffer = file_or_database==0 (0 for file)
            self.push_string_data_to_df(measurement_list, update_tp_table, tp_x)
        else:
            self.log_string_data_to_db(measurement_list, update_tp_table, tp_x)

    def log_float_data_to_db(self, measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        # todo: check tp_val type: dictionary like in mahoney; or idx to the tp_validation table; or tp_validation table
        if type(measurement_list) != type([]):
            measurement_list = [measurement_list]
        self.val_data_logger.log_float_data_to_db(measurement_list, tp_val)

    def log_string_data_to_db(self, measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        # todo: check tp_val type: dictionary like in mahoney; or idx to the tp_validation table; or tp_validation table
        if type(measurement_list) != type([]):
            measurement_list = [measurement_list]
        self.val_data_logger.log_string_or_file_data_to_db(measurement_list, 'string_data', tp_val)

    def log_file_data_to_db(self, measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        # todo: check tp_val type: dictionary like in mahoney; or idx to the tp_validation table; or tp_validation table
        if type(measurement_list) != type([]):
            measurement_list = [measurement_list]
        self.val_data_logger.log_string_or_file_data_to_db(measurement_list, 'file_data', tp_val)

    def push_float_data_to_df(self, measurement_list, update_tp_table = True, tp_x=None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        # Create empty rows
        if update_tp_table:
            self.update_tp_table()
        rows = []
        tp_val = self.table_to_dict(self.tp_table)

        # todo: check tp_val type: dictionary like in mahoney; or idx to the tp_validation table; or tp_validation table
        if not isinstance(measurement_list, list):
            measurement_list = [measurement_list]
        for measurement in measurement_list:
            #todo: log data one by one in case of self.df_size_limit <= len(measurement_list)
            vcorner_sql = f"SELECT * FROM vcorner WHERE vcorner_str = '{self.vcorner_str}'"
            _, vcorner_sql_results = self.container.db_proj.run_query(vcorner_sql)
            vcorner_details, *_ = vcorner_sql_results or ({},)
            tcorner_sql = f"SELECT * FROM tcorner WHERE tcorner_str = '{self.tcorner_str}'"
            _, tcorner_sql_results = self.container.db_proj.run_query(tcorner_sql)
            tcorner_details, *_ = tcorner_sql_results or ({},)
            env_details = {}
            for key, value in vcorner_details.items():
                if key not in ('id', 'vcorner_desc'):
                    env_details[key] = value
            for key, value in tcorner_details.items():
                if key not in ('id', 'tcorner_desc'):
                    env_details[key] = value
            tp_val_m = tp_val.copy()
            rows.append(dict(zip(
                self.val_data_logger.float_data_row_keys + ['env_details'],
                [measurement, tp_x.copy(), tp_val_m.copy(), env_details]
            )))
        if self.df_data_float is None:
            self.df_data_float = pd.DataFrame(rows)
        else:
            self.df_data_float = pd.concat([self.df_data_float,pd.DataFrame(rows)], ignore_index=True)
        self.df_size += len(measurement_list)
        if self.df_size >= self.df_size_limit: # todo: discuss if only force_log for log_to_dB
            self.force_log_val_data() # log all buffer, then reset self.df_size = 0

    def push_string_data_to_df(self, measurement_list, update_tp_table = True, tp_x =None):
        """
        Place Holder

        :param measurement_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        if type(measurement_list) != type([]):
            measurement_list = [measurement_list]
        for measurement in measurement_list:
            rows.append(dict(zip(self.val_data_logger.string_data_row_keys, [measurement, tp_x.copy(), tp_val.copy()])))
        if self.df_data_string is None:
            self.df_data_string = pd.DataFrame(rows)
        else:
            self.df_data_string = pd.concat([self.df_data_string, pd.DataFrame(rows)], ignore_index=True)

        self.df_size += len(measurement_list)
        if self.df_size >= self.df_size_limit: # todo: discuss if only force_log for log_to_dB
            self.force_log_val_data() # log all buffer, then reset self.df_size = 0

    def push_file_data_to_df(self, file_list, update_tp_table = True, tp_x =None):
        """
        Place Holder

        :param file_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        if type(file_list) != type([]):
            measurement_list = [file_list]
        for file in file_list:
            rows.append(dict(zip(self.val_data_logger.file_data_row_keys, [file, tp_x.copy(), tp_val.copy()])))
        if self.df_data_file is None:
            self.df_data_file = pd.DataFrame(rows)
        else:
            self.df_data_file = pd.concat([self.df_data_file, pd.DataFrame(rows)], ignore_index=True)

        self.df_size += len(file_list)
        if self.df_size >= self.df_size_limit: # todo: discuss if only force_log for log_to_dB
            self.force_log_val_data() # log all buffer, then reset self.df_size = 0

    def push_sweep_data_to_df(self, sweep_name, series_list, update_tp_table = True, tp_x =None, dut_id = None):
        """
        Place Holder

        :param sweep_name:
        :param series_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)

        sweep_data = dict(zip(self.val_data_logger.sweep_data_keys, [sweep_name, series_list, dut_id, tp_x.copy(), tp_val.copy()]))
        rows.append(sweep_data)

        if self.df_data_sweep is None:
            self.df_data_sweep = pd.DataFrame(rows)
        else:
            self.df_data_sweep = pd.concat([self.df_data_sweep, pd.DataFrame(rows)], ignore_index=True)

        self.df_size += 1
        if self.df_size >= self.df_size_limit: # todo: discuss if only force_log for log_to_dB
            self.force_log_val_data() # log all buffer, then reset self.df_size = 0

    def log_sweep_data_to_db(self, sweep_data, update_tp_table=True, tp_x=None):
        """
        Place Holder

        :param sweep_name:
        :param series_list:
        :param update_tp_table:
        :param tp_x:
        :return:
        """
        if tp_x is None:
            tp_x = {}
        if update_tp_table:
            self.update_tp_table()
        rows = []
        # tp_x = self.update_tp_x(tp_x)
        tp_val = self.table_to_dict(self.tp_table)
        sweep_data_i = dict(
            zip(self.val_data_logger.sweep_data_keys, [sweep_data.sweep_name, sweep_data.series_list, sweep_data.dut_id,
                                                       tp_x.copy(), tp_val.copy()]))
        #todo: check the dut_id and datagroup_id of sweep_data class

        self.val_data_logger.log_sweep_to_database(sweep_data_i)

    def log_val_data(self, start_new_session = False): #todo: check default value of skip_new_session
        """
        this method save the data from data_buffers(df_data_float/sweep/file/string) to csv_file or database, it clears
        the data_buffers after saving/logging
        """
        df_data_list = []
        if self.df_data_float is not None:
            df_data_list.append(self.df_data_float)
        if self.df_data_sweep is not None:
            df_data_list.append(self.df_data_sweep)
        if self.df_data_file is not None:
            df_data_list.append(self.df_data_file)
        if self.df_data_string is not None:
            df_data_list.append(self.df_data_string)

        if len(df_data_list)>0:

            if self.file_or_database == 0: # 0: to file
                for df_data in df_data_list:
                    # append to existing file if False, or add timestamp to filename if True.
                    self.val_data_logger.write_df_data_to_file(self.valdata_root_folder, self.project_test_name, df_data,
                                              self.filename_enable_timestamp)
                self.clear_df_data_buffers()
            elif self.file_or_database == 1: # to database
                if self.measurement_group is None:
                    self.measurement_group = self.project_test_name
                    self.measurement_group_desc = self.project_test_name
                #     measurement_group = 'todo' # self.project_test_name
                # if test_table_name is None:
                #     test_table_name = 'todo' # self.test_table_name #'validation'

                print("\033[93m Logging test results to database ...\033[0m")
                try:
                    self.setup_database_logging(force_new_session = start_new_session)

                    # loop over data in the df_data_list
                    self.val_data_logger.log_df_data_to_database(df_data_list)
                except Exception as dberr: # if fail logging to database, log it to csv files ....
                    print(dberr)
                    print("\033[93m Failed during Logging test results to database ...\033[0m")
                    print("\033[93m Now Logging it to csv files ...\033[0m")
                    # dut_id = self.dc_eeprom.GLOBAL.DUT_ID_0.DUT_ID.value
                    for df_data in df_data_list:
                        # append to existing file if False, or add timestamp to filename if True.
                        self.val_data_logger.write_df_data_to_file(self.valdata_root_folder, self.project_test_name,
                                                                   df_data, self.filename_enable_timestamp)

                self.clear_df_data_buffers()
            # elif self.file_or_database == 2: # preview
            #     pass
            else:
                pass

        elif self.file_or_database == 3:  # csv to database
            # filename = 'C:\\temp\\mahoney_temp_data\\logging_csv\\file-TestStandLogging-mahoney_emu-win10-20210510165714.csv'
            filename = 'C:\\temp\\mahoney_temp_data\\logging_csv\\float-TestStandLogging-mahoney_emu-win10-20210510165714.csv'
            self.val_data_logger.log_csv_to_database(filename, self.ignore_data, self.test_station, self.tp_val_keys, self.bay_number)
            # filename_2 = 'float-TestStandLogging-mahoney_emu-win10-20210510165714.csv'
            # filename_path_2 = os.path.join(self.valdata_root_folder, filename_2)
            # self.val_data_logger.log_csv_to_database(filename_path_2, 99, self.test_station, self.tp_val_keys, bay_number)
        else:
            pass

    def get_board_ids(self):
        """Returns the board_ids"""
        return [board[1].database_id for board in self.find_top_level().find_all(Board)]

    def get_dut_ids(self):
        """Returns the dut_ids. Raises an exception if an invalid DUT ID is provided"""
        duts = [dut[1] for dut in self.find_top_level().find_all(Dut)]
        dut_ids = [dut.database_id for dut in duts]
        return dut_ids

    def setup_database_logging(self, force_new_session = True):
        """
        Place Holder

        :param force_new_session:
        :return:
        """
        dut_id_list = self.get_dut_ids()
        board_id_list = self.get_board_ids()#[dc_board_id, eeb_board_id]
        self.val_data_logger.setup_database_logging(dut_id_list, board_id_list, self.bay_number)
        self.update_environment(self.vcorner_str, self.tcorner_str)
        self.start_new_session(force_start=force_new_session)
        # if self.measurement_group is None:
        self.set_measurement_group(self.measurement_group, self.measurement_group_desc)
        self.set_category()
        self.set_ignore_data()

    def set_measurement_group(self, measurement_group=None, measurement_group_desc=None):
        """
        Place Holder

        :param measurement_group:
        :param measurement_group_desc:
        :return:
        """
        if measurement_group is None:
            measurement_group = self.measurement_group
        if measurement_group_desc is None:
            measurement_group_desc = self.measurement_group_desc
        self.val_data_logger.set_measurement_group(measurement_group, measurement_group_desc)

    def set_category(self, test_category_desc=None):
        """
        Place Holder

        :param test_category_desc:
        :return:
        """
        if test_category_desc is None:
            test_category_desc = self.test_category_desc
        self.val_data_logger.get_category_id(test_category_desc)

    def set_ignore_data(self, ignore_data=None):
        """
        Place Holder

        :param ignore_data:
        :return:
        """
        if ignore_data is None:
            pass
        elif type(ignore_data) is int:
            self.ignore_data = ignore_data
        else:
            #todo: warning or error out on ignore_data type
            pass
        self.val_data_logger.set_ignore_data(self.ignore_data)

    def update_environment(self, vcorner_str=None, tcorner_str=None):
        """
        Place Holder

        :param vcorner_str:
        :param tcorner_str:
        :return:
        """
        self.update_vcorner_tcorner_str(vcorner_str, tcorner_str)
        self.val_data_logger.update_environment(self.vcorner_str, self.tcorner_str)

    def start_new_session(self, force_start = True):
        """
        Place Holder

        :param force_start:
        :return:
        """
        self.val_data_logger.start_new_session(force_start)

    def get_dut_list(self):
        """
        Place Holder

        :return:
        """
        #todo: scan through the test-station attrs
        pass

    def update_tp_table(self, *args, **kwargs):#dut=None):
        """
        Place Holder

        :param args:
        :param kwargs:
        :return:
        """
        #call corresponding handler based on test parameter table naming
        tp_table_name = self.container.data_logger.db_logging_dict['params_table_name'] #vdt.db_logging_dict['params_table_name
        self.tp_table = getattr(self.container.db_proj, tp_table_name)
        method_name = f'update_{tp_table_name}'
        if hasattr(self, method_name) and callable(getattr(self, method_name)):
            getattr(self, method_name)( *args, **kwargs) #dut)
        else:
            error_str = f"Fail to find the method: {method_name}, please ensure the corresponding method exists"
            raise ValueError(error_str)

    def clear_df_data_buffers(self):
        """Clear the df_data buffer after logging data"""
        # clear the df_data buffer after logging data
        self.df_data_float = None
        self.df_data_string = None
        self.df_data_sweep = None
        self.df_data_file = None
        self.df_size = 0

    def force_log_val_data(self):
        """
        Log all buffer. This will be called in case of:

            - self.df_size reaching limit
            - vcorner_str, tcorner_str changing
            - measurement_group changing
        """
        if self.df_size > 0:
            self.log_val_data(False)

    def update_vcorner_tcorner_str(self, vcorner_str, tcorner_str):
        """
        Place Holder

        :param vcorner_str:
        :param tcorner_str:
        :return:
        """
        if (self.vcorner_str == vcorner_str) & (self.tcorner_str == tcorner_str):
            pass # do nothing
        else:
            self.force_log_val_data()
            self.vcorner_str = vcorner_str
            self.tcorner_str = tcorner_str

    def update_measurement_group(self, measurement_group, description):
        """
        Place Holder

        :param measurement_group:
        :param description:
        :return:
        """
        if (self.measurement_group == measurement_group) & (self.measurement_group_desc == description):
            pass  # do nothing
        else:
            self.force_log_val_data()
            self.measurement_group = measurement_group
            self.measurement_group_desc = description

    def generate_id(self, level=1, recursive=True, dbg_dict=None):
        return 0


class Float_data():
    """Place Holder"""
    def __init__(self, measurement, description, value, units, dut_id=None, datagroup_id=None, limits_id=None,
                 limits_version=None, error_code=None, spec_tag=None):
        self.measurement = measurement
        self.description = description
        self.value = value
        self.units = units
        self.dut_id = dut_id
        self.datagroup_id = datagroup_id
        self.limits_id = limits_id
        self.limits_version = limits_version
        self.error_code = error_code
        self.spec_tag = spec_tag

class Series():
    """Place Holder"""
    def __init__(self,label, units, series_data, series_type=''):
        #series_keys = ['label', 'units', 'series_type', 'series_data']
        self.label = label
        self.series_data = series_data
        self.units = units
        self.series_type = series_type

class File_data():
    """Place Holder"""
    def __init__(self, measurement, description, file_path, file_dir, file_name, file_extension, dut_id=None, datagroup_id=None):
        self.measurement = measurement
        self.description = description
        self.file_path = file_path
        self.file_dir = file_dir
        self.file_name = file_name
        self.file_extension = file_extension
        self.dut_id = dut_id
        self.datagroup_id = datagroup_id

class String_data():
    """Place Holder"""
    def __init__(self, measurement, description, value, units='', dut_id=None, datagroup_id=None):
        self.measurement = measurement
        self.description = description
        self.value = value
        self.units = units
        self.dut_id = dut_id
        self.datagroup_id = datagroup_id

class Sweep_data():
    """Place Holder"""
    def __init__(self, sweep_name, series_list, dut_id=None, datagroup_id=None):
        self.sweep_name = sweep_name
        self.series_list = series_list
        self.dut_id = dut_id
        self.datagroup = datagroup_id
