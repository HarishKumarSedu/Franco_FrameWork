import logging
import sys
import os
import inspect
import csv
import traceback
from datetime import datetime
from math import ceil
from typing import Tuple
import atexit


# Globals to track error and warning counts
ERROR_COUNT = 0
WARNING_COUNT = 0


def log_wrapper(_log):
    """Wrapper for python's base logger class to track error and warning counts"""
    def inner(logger, level, msg, *args, **kwargs):
        if level == logging.WARNING:
            global WARNING_COUNT
            WARNING_COUNT += 1
        elif level == logging.ERROR:
            global ERROR_COUNT
            ERROR_COUNT += 1
        _log(logger, level, msg, *args, **kwargs)
    return inner


# Patch base logger with counter incrementers
logging.Logger._log = log_wrapper(logging.Logger._log)


class ColorFormatter(logging.Formatter):
    """**Logging Formatter to add colors and count warning / errors**"""

    green = '\033[92m'
    grey = "\033[38m"
    yellow = "\033[93m"
    red = "\033[31m"
    bold_red = "\033[31;1m"
    light_red = "\033[31;2m"
    cyan = "\033[1;36m"
    reset = "\033[0;0m"
    format = "%(asctime)s - %(levelname)-8s - %(message)s"

    FORMATS = {
        5:                cyan     + format + reset,
        logging.DEBUG:    green    + format + reset,
        logging.INFO:     grey     + format + reset,
        logging.WARNING:  yellow   + format + reset,
        logging.ERROR:    red      + format + reset,
        logging.CRITICAL: bold_red + format + reset
    }

    def format(self, record):
        log_fmt = self.FORMATS.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)

class TsLoggingAdapter(logging.LoggerAdapter):

    DEV = 5
    DEBUG = logging.DEBUG
    INFO = logging.INFO
    WARNING = logging.WARNING
    ERROR = logging.ERROR
    CRITICAL = logging.CRITICAL

    def __init__(self, logger, ts_path:str, resources:dict=None):
        super().__init__(logger=logger, extra={'ts_path': ts_path})
        if 'DEV' not in logging._nameToLevel:
            logging.addLevelName(self.DEV, 'DEV')
        self.resources = resources
        self.container_path = '.'.join(ts_path.split('.')[:-1])
        self.gt_warning_flag = False  # Greater than warning - indicates whether line number and file will be added
        self.lineno   = None
        self.filename = None
        self.__suppress_file_msg = False

    def process(self, msg, kwargs):
        just = 0
        if self.resources:
            just = len(self.container_path) + 1 + max([len(n) for n in self.resources.keys()])  # Add one for period
        if self.gt_warning_flag:
            self.gt_warning_flag = False
            if not self.__suppress_file_msg:
                msg += ' (File "%s", line %d)' % (self.filename, self.lineno)
            else:
                self.__suppress_file_msg = False

        return '%s - %s' % (self.extra['ts_path'].ljust(just), msg), kwargs

    def warning(self, msg, *args, suppress_file_msg=False, **kwargs):
        self.gt_warning_flag = True
        self.filename, self.lineno = self.get_stack_info()
        self.__suppress_file_msg = suppress_file_msg
        super().warning(msg, *args, **kwargs)

    def error(self, msg, *args,  suppress_file_msg=False, **kwargs):
        self.__suppress_file_msg = suppress_file_msg
        self.gt_warning_flag = True
        self.filename, self.lineno = self.get_stack_info()
        super().error(msg, *args, **kwargs)

    def exception(self, msg, *args, suppress_file_msg=False, **kwargs):
        self.gt_warning_flag = True
        self.__suppress_file_msg = suppress_file_msg
        self.filename, self.lineno = self.get_stack_info()
        # super().exception(msg, *args, **kwargs)
        self.error(msg, *args, suppress_file_msg=suppress_file_msg, **kwargs)
        self.print(ColorFormatter.light_red + traceback.format_exc() + ColorFormatter.reset)
        for handler in self.logger.handlers:
            if handler.stream.writable():
                handler.stream.write('\n')

    def critical(self, *args, suppress_file_msg=False, **kwargs):
        self.gt_warning_flag = True
        self.__suppress_file_msg = suppress_file_msg
        self.filename, self.lineno = self.get_stack_info()
        super().critical(*args, **kwargs)

    def dev(self, msg):
        self.logger.log(self.DEV, msg)

    def get_stack_info(self):
        frame = inspect.stack()[2]  # Caller of log function
        return frame.filename, frame.lineno

    def pop_counts(self):
        global ERROR_COUNT, WARNING_COUNT
        e, w = ERROR_COUNT, WARNING_COUNT
        ERROR_COUNT, WARNING_COUNT = 0, 0
        return e, w

    def pop_and_display_counts(self, msg) -> Tuple[int, int]:
        """
        Prints message displaying the total number of errors and warning since the last call to pop_counts(). Returns
        Tuple containing the error and warning counts.

        :param msg: Message to display to the screen along with the counts
        :type msg: str
        :return: Tuple (error_count, warning_count)
        :rtype: tuple
        """
        e, w = self.pop_counts()
        red = '\033[31m'
        yellow = '\033[93m'
        rst = '\033[0m'
        e_str = (red    if e > 0 else rst) + str(e) + ' ERROR'   + ('S' if e != 1 else '') + rst
        w_str = (yellow if w > 0 else rst) + str(w) + ' WARNING' + ('S' if w != 1 else '') + rst
        self.info(msg + ', encountered %s, %s.' % (e_str, w_str), border='=')
        return e, w

    def info(self, msg, *args, border='', **kwargs):
        num_chars = 103 - len(self.process('', {})[0])
        if border:
            super().info(border*num_chars, *args, **kwargs)
        super().info(msg, *args, **kwargs)
        if border:
            super().info(border*num_chars, *args, **kwargs)

    def info_line(self, char='='):
        num_chars = 103 - len(self.process('', {})[0].expandtabs())
        super().info(char * int(num_chars/len(char)))

    def draw_line(self, char='=', level='INFO'):
        try:
            level = logging._levelToName[level] if type(level) is int else level
            if level in logging._nameToLevel:
                func_name = level.lower()
            else:
                raise KeyError
        except KeyError:
            raise ValueError("Given level did not match a log level. Supported values: %s" % str(logging._nameToLevel))
        num_chars = 180 - len(self.process('', {})[0])
        self.__getattribute__(func_name)((char*num_chars)[:num_chars])

    def print(self, msg, *args, end='\n'):
        if type(msg) is not str:
            msg = str(msg)
        for extra in args:
            msg += ' ' + str(extra)
        for handler in self.logger.handlers:
            if handler.stream is not None and handler.stream.writable():
                handler.stream.write(msg+end)  # Write message into the stream buffer
                handler.stream.flush()  # Send to destination

    def setLevel(self, level):
        super().setLevel(level)
        self.logger.setLevel(level)
        for handler in self.logger.handlers:
            handler.setLevel(level)

    @property
    def handlers(self):
        if hasattr(self.logger, 'handlers'):
            return self.logger.handlers
        elif hasattr(self.logger, 'logger') and hasattr(self.logger.logger, 'handlers'):
            return self.logger.logger.handlers
        else:
            return []


FMT = '%(asctime)s - %(levelname)-8s -- %(message)s'

def get_logger():
    logger = logging.getLogger('cl_test_station')
    return logger

def add_file_handler(logger, filename):
    if not os.path.exists(os.path.dirname(filename)):
        os.makedirs(os.path.dirname(filename))
    fhandler = logging.FileHandler(filename=filename, encoding='utf-8', mode='w+')
    fhandler.setLevel(logging.INFO)
    fhandler.setFormatter(logging.Formatter(FMT))
    logger.addHandler(fhandler)

def add_stream_handler(logger, out=sys.__stdout__):
    shandler = logging.StreamHandler(out)
    shandler.setLevel(logging.INFO)
    shandler.setFormatter(ColorFormatter())
    logger.addHandler(shandler)


class TransactionLogger:
    """**Class that handles transaction logging for entire test station. Will be an attribute under the top level
    TSO**"""

    ROWS = ['Time Stamp', 'Delta (seconds)', 'Component', 'Address', 'Reg Name', 'Field Name(s)', 'Description', 'Reg Value',
            'Field Value(s)', 'Interface', 'Host Controller', 'Calling Function', 'Call Stack', 'Error Status', 'Notes']

    def __init__(self):
        self._tracked_objects = {}  # type: Dict[str, dict]
        self.current_time = None
        atexit.register(self.close_all_streams)  # This function will run before garbage collector destroys everything

    def add_csv_stream(self, log_file, append):
        """
        Opens 'log_file' as a CSV writer and allows components to be tracked by the log file with track()

        :param log_file: Path to csv log file (must end in .csv)
        :type log_file: str
        :param append: When False, deletes log_file if it exists and creates an empty log file. When True and log_file
            already exists, the logger will just open the file, keeping previous log entries.
        :type append: bool
        :return: None
        """
        if not log_file.endswith('.csv'):
            raise ValueError("Log file must be csv: %s" % os.path.basename(log_file))
        stream = open(log_file, 'a', newline='')  # Open log file
        writer = csv.writer(stream)
        if not append:  # Need to truncate and add header rows to new file
            stream.truncate(0)  # Clear file contents
            stream.seek(0)  # Move pointer to start of file
            writer.writerow(self.ROWS)  # Create header row
            stream.flush()
        self._tracked_objects[log_file] = {'stream': stream, 'writer': writer}  # Init log_file as empty dict

    def track(self, tso_path, log_file=None, call_stack=True, append=False):
        """
        Tracks transactions for component with path 'tso_path' under file 'log_file'. If 'log_file' is None, component
        will be tracked by all files already specified in the this class.

        :param tso_path: dot path to component, eg 'test_station.board.dut'
        :type tso_path: str
        :param log_file: path to specific CSV log file
        :type log_file: str
        :param call_stack: When True, function call and stack history will be included in log file.
            **NOTE: Enabling this feature will increase time between transactions by about 10ms**
        :type call_stack: bool
        :param append: When False, deletes log_file if it exists and creates an empty log file. When True and log_file
            already exists, the logger will append to the end of the file, keeping previous log entries.
        :type append: bool
        :return: True if component is tracked by any file in the Logger
        :rtype: bool
        """
        if log_file:  # Track for specific stream
            if log_file not in self._tracked_objects or self._tracked_objects[log_file]['stream'].closed:
                self.add_csv_stream(log_file, append)  # Initilize log file stream
            self._tracked_objects[log_file][tso_path] = {'en': True, 'call_stack': call_stack}  # Track component
        else:  # Track given component for all Streams
            if self._tracked_objects.keys():
                for log_file in self._tracked_objects.keys():
                    self.track(tso_path, log_file, append)
            else:
                raise KeyError("No Log file specified, add at least one file to enable transaction logging")
        return self.is_enabled(tso_path)

    def untrack(self, tso_path, log_file=None):
        """
        Disables transaction logging for component with path 'tso_path'. If log_file is not specified, component will
        be disabled for all log files

        :param tso_path: dot path to component, eg 'test_station.board.dut'
        :type tso_path: str
        :param log_file: path to specific CSV log file
        :type log_file: str
        :return: True if component is tracked by any file in the Logger
        :rtype: bool
        """
        if log_file:  # Untrack for specific stream
            if log_file in self._tracked_objects:  # Set enabled to False
                self._tracked_objects[log_file][tso_path]['en'] = False
                # If all components are disabled for the file, close the file's stream
                registered_component_states = [state for state in self._tracked_objects[log_file].values() if type(state) is dict]
                if all(not state['en'] for state in registered_component_states):  # Close stream
                    self._tracked_objects[log_file]['stream'].close()
        else:  # Untrack for all streams
            for log_file in self._tracked_objects.keys():
                if tso_path in self._tracked_objects[log_file]:
                    self.untrack(tso_path, log_file)

        return self.is_enabled(tso_path)

    def log(self, tso_path, address, addr_size, reg_name, field_name, desc, value, data_size, iface_name, hc_name,
            field_value, exc=None, notes=None):
        """
        Creates new log entry (row) representing a completed component transaction. Based on the component's 'tso_path'
        given, will write the entry to any log_file tracking that component.

        :param tso_path: dot path to component, eg 'test_station.board.dut'
        :type tso_path: str
        :param address: Memory address of the transaction
        :type address: int
        :param addr_size: Length in Bytes of the address
        :type addr_size: int
        :param field_name: Name of access point, eg Register/Field. Will be of form BLOCK_NAME.REG_NAME.FIELD_NAME
        :type field_name: str
        :param desc: Brief description of the transaction. eg. was is a read, write, verify, etc.
        :type desc: str
        :param value: Integer value of what was read/written
        :type value: int
        :param data_size: Length in Bytes of the register
        :type data_size: int
        :param iface_name: Reference name of interface used eg. dut_i2c, SPI, etc
        :type iface_name: str
        :param hc_name: Reference name of host controller used eg. audio_hub
        :type hc_name: str
        :param field_value: Value of field read/written. Hex notation. If transaction was register r/w, this param should be None
        :type field_value: str
        :return: None
        """
        self.prev_time = self.current_time
        self.current_time = datetime.today()
        component_fp = os.path.normpath('cl_test_station/components/component/component.py')
        timestamp = self.current_time.strftime(' %Y-%m-%d %H:%M:%S.%f')  # Leading space to prevent excel formatting
        delta = None if self.prev_time is None else (self.current_time - self.prev_time).total_seconds()
        # Format integer columns as zero-filled hex
        if type(address) is int:
            if addr_size:
                address = f'0x{hex(address)[2:].zfill(addr_size << 1)}'  # Zero-fill address to correct length
            else:
                address = hex(address)
        if type(value) is int:
            if data_size:
                value = f'0x{hex(value)[2:].zfill(data_size << 1)}'
            else:
                value = hex(value)
        # Build exception string
        if isinstance(exc, Exception):
            exc = repr(exc)
        else:
            exc = 'No Error'
        # Build multiline columns if applicable
        if type(field_value) is list:
            field_value = '\n'.join(field_value)
        if type(field_name) is list:
            field_name = '\n'.join(field_name)

        for log_file, contents in self._tracked_objects.items():  # Loop over each stream
            if tso_path in contents and contents[tso_path]['en']:  # Component is enabled for this stream
                caller = None
                component_caller = None
                call_path = []
                if contents[tso_path]['call_stack']:  # Get calling function and build full call stack
                    stack = inspect.stack()
                    # Iterate through the stack
                    for i, frameinfo in enumerate(stack):
                        f_locals = frameinfo.frame.f_locals
                        if 'self' in f_locals:
                            call_path.append('%s.%s()' % (f_locals['self'].__class__.__name__, frameinfo.function))
                        # Find component level function that was called
                        if not component_caller and component_fp in os.path.normpath(frameinfo.filename):
                            component_caller = f'{os.path.basename(frameinfo.filename)}, line {frameinfo.lineno}, {frameinfo.function}()'
                        # Find the first external function in the stack that resulted in the .value call
                        if not caller and (frameinfo.function == 'value' or frameinfo.function=='log_poll_transaction'):
                            i += 1
                            while stack[i].function.startswith('__'):
                                i += 1
                            caller = '%s, line %d, %s()' % (os.path.basename(stack[i].filename), stack[i].lineno, stack[i].function)
                        elif not caller and stack[i].function == 'poll':
                                i += 1
                                caller = '%s, line %d, %s()' % (os.path.basename(stack[i].filename), stack[i].lineno, stack[i].function)
                        # For validation environments, end the call stack at the UM level
                        if frameinfo.function in ['run_test', 'setup', 'initiate', 'complete', 'teardown', '<module>']:
                            break
                    if not caller:  # Nothing called .value, use component caller instead
                        caller = component_caller
                # Seek to the first new row of the csv
                contents['stream'].seek(0, os.SEEK_END)
                # Write the row to the csv
                contents['writer'].writerow([timestamp, delta, tso_path, address, reg_name, field_name, desc, value,
                                             field_value, iface_name, hc_name, caller,
                                             ' -> '.join(reversed(call_path[1:-1])), exc, notes])
                # Flush buffer so that users can view log in real time
                contents['stream'].flush()

    def is_enabled(self, tso_path):
        """
        Checks every log_file stream and returns True if 'tso_path' is enabled for at least one stream.

        :param tso_path: dot path to component, eg 'test_station.board.dut'
        :type tso_path: str
        :return: True if tso_path is tracked by at least one stream, False otherwise
        :rtype: bool
        """
        for log_file, contents in self._tracked_objects.items():  # Loop through each stream
            if tso_path in contents and contents[tso_path]['en']:  # Enable flag for the stream
                return True
        return False  # Not enabled for any stream

    def close_all_streams(self):
        """
        Runs at interpreter termination, closes all log file streams

        :return: None
        """
        for contents in self._tracked_objects.values():
            contents['stream'].close()
