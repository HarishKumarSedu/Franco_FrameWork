"""
Script for expanding YAML files with custom sytax.
Author: Evan Canter
"""
import yaml, os, re, json
from cl_test_station.utilities.varilist import VariList, enumerate
from io import StringIO, IOBase
from typing import List, Tuple, Any

# iterator_regex = re.compile(r'\{(\w+),(\d+|[a-zA-Z]+):(\d+|[a-zA-Z]+)\}')
iterator_regex = re.compile(r'\{(\w+),\s*(.+?)\}')
range_regex = re.compile(r'(\d+|[a-zA-Z]+):(\d+|[a-zA-Z]+)')
exp_range_regex = re.compile(r'\[(\w+(,\w+)+)\]')
list_regex =  re.compile(r'\[(\w+),\s*(\[.+?\]|\w+:\w+)\]')
KEYWORD = '__CL_YAML_REPLACE__'
_obj = None
_fname = ''
parameters = {}


class FullLoaderWithBuffer(yaml.FullLoader):
    """YAML's internal 'buffer' attribute only stores chunks of 4096 characters. This loader reads the entire file and
    stores it in a new attribute '_buffer'. This enables !attr and !param constructors that rely on stream contents"""

    def __init__(self, stream):
        if not isinstance(stream, IOBase):
            raise TypeError(f"Loader input stream can only be an IO Stream, not {type(stream)}")
        self._buffer = None
        # Read entire stream and restore location
        loc = stream.tell()
        stream.seek(0)
        self._buffer = stream.read()
        stream.seek(loc)
        super().__init__(stream)


def attr_constructor(loader, node):
    key, line = param_constructor(loader, node)
    attr = _obj
    for attr_name in parameters[key].split('.'):
        try:
            attr = eval(f'attr.{attr_name}')
        except AttributeError:
            raise yaml.error.YAMLError(
                f'Obect {_obj} has no attribute {attr_name}. File "{_fname}", line {node.start_mark.line + 1}\n\t{line}')

    parameters[key] = attr
    return key, line

def param_constructor(loader: yaml.Loader, node: yaml.Node):
    mark:yaml.error.Mark = node.start_mark
    line = loader._buffer.split('\n')[mark.line]  # Get line from buffer
    key = line[:mark.column].rpartition(':')[0]  # Get Key from line
    if re.match(r'\s+', key):
        raise yaml.error.YAMLError(f'Can only use {node.tag} at top level: File "{_fname}", line {mark.line+1}\n\t{line}')
    parameters[key] = node.value
    return key, line


def yaml_load(fname:str, obj=None) -> dict:
    """
    Loads fname as yaml file into dictionary. Then expands dictionary with custom iterator syntax.

        eg. {y,1:10} iterates {y} from 1 through 9

    **key{x,0:2}:**

        **value{x}: {x}**

    **will become:**

    **key0:**

        **value0: 0**

    **key1:**

        **value1: 1**

    :param fname: Path to .yml file to load into dictionary
    :type fname: str
    :param obj: Optional object reference used solely for parametrizing using object attributes
    :return: dictionary
    """
    if not fname.endswith('.yml'):
        raise NameError("Only .yml files supported")
    if not os.path.isfile(fname):
        raise FileNotFoundError(fname)
    # Set obj global so that constructor can get_attribute
    global _obj, _fname, parameters
    _obj = obj
    _fname = fname
    parameters = {}
    # Transfer file contents to StringIO stream to prevent editor memory conflicts
    stream = __create_stream(fname)
    # Load YAML into dictionary
    loader = FullLoaderWithBuffer
    loader.add_constructor('!attr', attr_constructor)
    loader.add_constructor('!param', param_constructor)
    d = yaml.load(stream, Loader=loader)
    # Once dict is loaded, stream is not needed anymore
    stream.close()
    if not d: # Empty file, skip parsing entirely
        return {}
    contents = json.dumps(d)
    # Replace parameter references with their defined values
    d, contents = __replace_params(contents)
    # Loop through d and expand iterators
    iterator_match = iterator_regex.search(contents)
    while iterator_match:
        d = expand_dict(d, func=expand_iterator, regex=iterator_regex)
        contents = json.dumps(d)
        iterator_match = iterator_regex.search(contents)
    # Loop through d and expand lists
    list_match = list_regex.search(contents)
    while list_match:
        d = expand_dict(d, func=expand_list, regex=list_regex)
        contents = json.dumps(d)
        list_match = list_regex.search(contents)
    return remove_keywords(d)

def __replace_params(contents):
    for param_name, param_value in  parameters.items():
        if param_value is not None:
            param_value = json.dumps(param_value)
            contents = contents.replace(f'${param_name}', param_value.replace('"', ''))
        else:
            contents = contents.replace(f'"${param_name}"', 'null')
    d = json.loads(contents)
    for key in parameters.keys():
        d.pop(key)
    return d, contents

def __create_stream(file:str) -> StringIO:
    """
    Makes file yaml compatible, in case { or [ are at start of keys/values. Also parses parameters and replaces param
    refs.

    :param file:  YAML file to prepare
    :type file: str
    :return: StringIO stream with keywords inserted
    :rtype: StringIO
    """
    with open(file, 'r') as f:
        contents = f.readlines()
    for i, line in enumerate(contents):
        if line.strip().startswith('#') or not line.strip():  # Skip blank and commented lines
            continue
        if line.strip().startswith('-'):  # List entry
            char = '-'
        elif ':' in line:  # Dict entry
            char = ':'
        else:  # Skip, will error out otherwise
            continue
        key, sep, value = line.rpartition(re.findall(fr'{char}\s+', line)[-1])  # Split up key and value
        sep = sep.replace('\n', '')
        key_whitespace = re.search(r'\s*', key).group(0)
        key = key.strip()
        if key.strip().startswith('{') or key.strip().startswith('['):  # Need to insert keyword into key
            key = KEYWORD + key
        val_whitespace = re.search(r'\s*', value.replace('\n', '')).group(0)
        value = value.strip()
        if value.strip().startswith('{') or value.strip().startswith('['):  # Insert keywork into value
            value = KEYWORD + value
        contents[i] = key_whitespace + key.replace(' ', '') + sep + val_whitespace + value + '\n'
    stream = StringIO()
    stream.writelines(contents)
    stream.seek(0)
    return stream

def remove_keywords(d:dict) -> dict:
    """
    Recursively searches through yaml dictionary and removes KEYWORD = __CL_YAML_REPLACE__ from all keys/values.
    Note: Cannot use JSON dump and string replace since Varilists are not JSON serializable

    :param d: Target dictionary
    :type d: dict
    :return: New dictionary with all keywords replaced
    :rtype: dict
    """
    d_json = __json_dumps(d)
    d_json = d_json.replace(KEYWORD, '')
    return __json_loads(d_json)


# TODO: Remove PLATDEV-1080
def __remove_kw_list_helper(l:list) -> list:
    if type(l) is VariList:
        _l = VariList(start_index=l.start_index)
    elif type(l) is list:
        _l = []
    for i, item in enumerate(l):
        if type(item) is str:
            _l.append(item.replace(KEYWORD, ''))
        elif type(item) is dict:
            _l.append(remove_keywords(item))
        elif isinstance(item, list):
            _l.append(__remove_kw_list_helper(item))
        else:
            _l.append(item)

    return _l


def expand_dict(d:dict, func, regex) -> dict:
    """
    Loops through entire dictionary and expands any iterators found

    :param d: [dict] Target dictionary to expand
    :param _type: [str] 'iter' for iterator expansion, 'list' for list expansion
    :return: None
    """
    for key, value in list(d.items()):  # Convert to list since size will change
        if type(value) is dict:  # Recursively expand
            d[key] = expand_dict(value, func, regex)
        match = regex.search(key)
        if match:
            func(d, key)  # Expand this key-value pair
    return d


# TODO: PLATDEV-1080 Remove
def expand_list_iterators(d:dict) -> dict:
    """
    Loops through entire dictionary and expands any iterators found

    :param d: [dict] Target dictionary to expand
    :param type: [str] 'iter' for iterator expansion, 'list' for list expansion
    :return: None
    """
    for key, value in list(d.items()):
        if type(value) is dict:  # Recursively expand
            d[key] = expand_list_iterators(value)
        match = list_regex.search(key)
        if match:
            expand_list(d, key)
    return d

def get_range(range_def:str) -> list:
    """
    Takes in string representing values and return list of those explicit values
    eg. 2:6 returns ['2','3','4','5','6'], "[1,2,3,abc]" returns ['1','2','3','abc']

    :param range_def: string representing list
    :return: List[str]
    """
    range_match = range_regex.search(range_def)
    if range_match:  # Get start, end and make list
        start = range_match.group(1)
        end = range_match.group(2)
        reverse = False
        if start.isdigit() and end.isdigit():  # Range of ints
            if int(start) > int(end):  # Descend if start is bigger than end
                reverse = True
                values = [str(n).zfill(len(end)) for n in range(int(end), int(start)+1)]
            else:
                values = [str(n).zfill(len(start)) for n in range(int(start), int(end)+1)]
        else:  # Assume range of letters
            if ord(start) > ord(end):  # Descend
                reverse = True
                values = list(map(chr, range(ord(end), ord(start)+1)))
            else:
                values = list(map(chr, range(ord(start), ord(end)+1)))
        if reverse:
            values = list(reversed(values))
        return values
    list_match = exp_range_regex.search(range_def)
    if list_match:
        return list_match.group(1).split(',')

def expand_iterator(d:dict, key:str):
    """
    Expands key in d based on iterator

    :param d: Input dictionary
    :type d: dict
    :param key: key containing iterator
    :type key: str
    :return: None
    """
    match = iterator_regex.search(key)
    if not match:
        return
    iterator = match.group(0)  # Full iterator definition
    var = match.group(1)  # Variable name to replace with number
    range_def = match.group(2)  # values
    new_entries = {}
    value_json = json.dumps(d[key])  # Dumping to a string makes replacing all nested values trivial
    for i in get_range(range_def):
        key_insert = __match_case(var, i)
        new_key = key.replace(iterator, key_insert)  # Update key with var
        # new_value_json = value_json.replace('{%s}' % var, i)  # Update any var reference in the value
        new_value_json = __replace_var_ref(value_json, (var, i), square=False)
        new_entries[new_key] = json.loads(new_value_json)
    d.pop(key)  # Remove iterator template
    d.update(new_entries)  # Add expanded key-value pairs

def expand_list(d:dict, key:str):
    matches = list(list_regex.finditer(key))
    if not matches:
        return
    match = matches[-1]
    iterator = match.group(0)  # Full iterator definition
    var = match.group(1)  # Variable name to replace with number
    list_def = match.group(2)
    list_values = get_range(list_def)
    if ':' in list_def and all([n.isdigit() for n in list_values]):
        start_index = int(min(list_values, key=int))
        if start_index > 0:
            new_value = VariList(start_index=start_index)
        else:
            new_value = []
    else:
        new_value = []
    value_json = __json_dumps(d[key])
    for i in list_values:
        # new_value_json = value_json.replace('[%s]' % var, i)
        new_value_json = __replace_var_ref(value_json, (var, i), square=True)
        new_value.append(__json_loads(new_value_json))
    new_key = key.replace(iterator, '')  # Remove list definition
    d.pop(key)
    d[new_key] = new_value

def __json_dumps(item):
    __prepend_varilists(item)
    result = json.dumps(item)
    __create_varlists(item)
    return result

def __prepend_varilists(item):
    if isinstance(item, VariList):
        for sub_item in item:
            __prepend_varilists(sub_item)
        item.insert(0, '__CL_VARILIST__')
        item.insert(1, item.start_index)
    elif type(item) is list:
        for sub_item in item:
            __prepend_varilists(sub_item)
    elif type(item) is dict:
        for value in item.values():
            __prepend_varilists(value)

def __json_loads(string):
    item = json.loads(string)
    item = __create_varlists(item)
    return item

def __create_varlists(item):
    if isinstance(item, list):
        for i, sub_item in enumerate(item):
            item[i] = __create_varlists(sub_item)
        start = item.start_index if type(item) is VariList else 0
        if item[start] == '__CL_VARILIST__':
            return VariList(init_list=item[start+2:], start_index=item[start+1])
    if type(item) is dict:
        for key, value in item.items():
            item[key] = __create_varlists(value)
    return item

def __replace_var_ref(value:str, var:Tuple[str, Any], square:bool) -> str:
    """
    Take YAML value, eg SOME_THING{x+1} and replaces the variable name 'x' with its real value. Does comp if nec.

    :param value: Full value string
    :type value: str
    :param var: Tuple containing variable name and value
    :type var: tuple
    :param square: type of bracket, True = [], False = {}
    :type square: bool
    :return: New string with the variable replaced
    :rtype: str
    """
    var_name, var_value = var
    if square:
        open, close = r'\[', r'\]'
    else:
        open, close = r'\{', r'\}'

    valid_chars = fr"0-9.\+ \-*\/\|\^\&\~\%\(\)<>{var_name.lower()}{var_name.upper()}"
    ref_search = re.compile(f"({open}([{valid_chars}]+){close})")  # Searches for whats in the brackets, eg {x/2 + 1}
    invalid_search = re.compile(f"[^{valid_chars}]")  # Sniffs out non computational code
    for whole, inner in ref_search.findall(value):  # All {}, [] in value
        if invalid_search.match(inner):  # Found an invalid character, skip this one
            continue
        if var_value.isdigit():
            zfill = 0
            if len(var_value) > 1 and var_value.startswith('0'):  # User entered a zero-filled range
                zfill = len(var_value)  # Capture zfill amount
                stripped_var_value = var_value.lstrip('0')  # Strip leading 0's to prevent invalid token error in eval
                if not stripped_var_value:  # All zero's
                    stripped_var_value = '0'
            else:
                stripped_var_value = var_value
            inner = re.compile(var_name, re.IGNORECASE).sub(stripped_var_value, inner)  # Replace var name with number, case insensitive
            comp_var_value = str(eval(inner)).zfill(zfill)  # Compute variable value for this replacement with correct zfill
        else:  # Normal string, apply case
            comp_var_value = __match_case(inner, var_value)
        # Replace the computed value with the while {} or [] definition
        value = value.replace(whole, str(comp_var_value))
    return value

def __match_case(key:str, other:str):
    """
    Returns string reprenting 'other', case matched to conform with 'key'. For example, if key is upper and other is lower,
    this function will return other.upper()

    :param key: String to conform caasing to
    :type key: str
    :param other: String to convert
    :type other: str
    :return: Conformed string whose letters match 'other', but whose casing matches 'key'
    :rtype: str
    """
    if key.islower():  # Make other lower
        return other.lower()
    elif key.isupper():  # Make other upper
        return other.upper()
    else:  # Maintain current casing
        return other


def load_and_expand_yaml(fname: str, loader: yaml.Loader = yaml.FullLoader) -> dict:
    """
    Reads yaml file, converts all environmental variable references and loads dictionary.

    :param fname: Path to .yml file
    :type fname: str
    :param loader: YAML loader to use. Defaults to FullLoader
    :type laoder: yaml.Loader
    :return: Loaded dictionary
    :rtype: dict
    """
    # Expand file path
    fname = os.path.expandvars(fname)
    # Read in raw file contents
    with open(fname, 'r') as f:
        contents = f.read()
    # Expand ENV variables
    contents = os.path.expandvars(contents)
    # Convert slashes
    contents = contents.replace(os.sep, '/')
    # Write modified contents to new stream
    stream = StringIO()
    stream.write(contents)
    stream.seek(0)
    # Load and return dictionary
    loaded_dict = yaml.load(stream, Loader=loader)
    # yaml.load will return None if the file is empty, an empty dict is easier to deal with
    if loaded_dict is None:
        loaded_dict = {}
    return loaded_dict
